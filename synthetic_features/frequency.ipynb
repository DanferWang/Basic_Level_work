{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score, balanced_accuracy_score\n",
    "from itertools import combinations\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                              Synsets domain_x  nrdirhypers_x  nrhypos_x  \\\n0    Synset('adjustable_wrench.n.01')     tool              1          7   \n1         Synset('allen_wrench.n.01')     tool              1          0   \n2     Synset('alligator_wrench.n.01')     tool              1          0   \n3                  Synset('awl.n.01')     tool              1          2   \n4              Synset('backsaw.n.01')     tool              1          0   \n..                                ...      ...            ...        ...   \n834       Synset('ballet_skirt.n.01')     garm              1          0   \n835        Synset('mess_jacket.n.01')     garm              1          0   \n836         Synset('long_johns.n.01')     garm              1          0   \n837             Synset('undies.n.01')     garm              1          0   \n838           Synset('lingerie.n.01')     garm              1          2   \n\n     nrpartrels_normalised_x  depthfromtopsynset_normalised_x  \\\n0                        0.0                         1.012903   \n1                        0.0                         1.012903   \n2                        0.0                         1.012903   \n3                       15.7                         0.911613   \n4                        0.0                         1.114194   \n..                       ...                              ...   \n834                      0.0                         0.947552   \n835                      0.0                         1.158120   \n836                      0.0                         1.052836   \n837                      0.0                         1.158120   \n838                      0.0                         1.052836   \n\n     glosslength_normalised_x  minwordlength_x  nroflemmas_x  polyscore_max_x  \\\n0                    0.563173               17             2                1   \n1                    0.391092               12             1                1   \n2                    1.517437               16             1                1   \n3                    0.985552                3             1                1   \n4                    1.110701                7             2                1   \n..                        ...              ...           ...              ...   \n834                  0.578283                4             2                2   \n835                  1.652238               11             3                1   \n836                  0.479149               10             1                1   \n837                  0.280880                6             1                1   \n838                  0.561761                8             2                1   \n\n     ... ngram_50y_max  ngram_100y_mean  ngram_100y_max  ngram_200y_mean  \\\n0    ...  5.067315e-08     2.252890e-08    5.067315e-08     1.380492e-08   \n1    ...  6.483798e-08     1.515313e-08    6.483798e-08     7.715051e-09   \n2    ...  5.970550e-10     6.184165e-10    7.804026e-09     1.237592e-09   \n3    ...  3.752697e-07     3.562540e-07    6.002532e-07     5.869817e-07   \n4    ...  2.446695e-08     1.704462e-08    2.446695e-08     1.451245e-08   \n..   ...           ...              ...             ...              ...   \n834  ...  8.004256e-07     2.485961e-07    8.004256e-07     1.531570e-07   \n835  ...  8.272560e-09     1.233276e-08    2.136213e-08     1.358353e-08   \n836  ...  1.103470e-07     2.680743e-08    1.103470e-07     1.393969e-08   \n837  ...  2.565946e-07     5.787213e-08    2.565946e-07     3.095668e-08   \n838  ...  1.126403e-06     4.927242e-07    1.126403e-06     2.835355e-07   \n\n     ngram_200y_max  ngram_400y_mean  ngram_400y_max  ngram_500y_mean  \\\n0      5.067315e-08     6.919673e-09    5.067315e-08     5.336133e-09   \n1      6.483798e-08     3.867145e-09    6.483798e-08     2.982164e-09   \n2      1.499339e-08     6.203393e-10    1.499339e-08     4.783770e-10   \n3      2.510665e-06     6.210211e-07    6.602901e-06     5.069033e-07   \n4      3.507272e-08     9.018908e-09    2.260505e-07     6.954965e-09   \n..              ...              ...             ...              ...   \n834    8.004256e-07     1.136149e-07    8.004256e-07     9.223624e-08   \n835    5.083992e-08     6.963715e-09    5.547362e-08     5.370096e-09   \n836    1.103470e-07     6.987224e-09    1.103470e-07     5.388225e-09   \n837    2.565946e-07     2.025520e-08    3.896998e-07     1.561987e-08   \n838    1.126403e-06     1.440483e-07    1.126403e-06     1.351753e-07   \n\n     ngram_500y_max  bnc_100m_sum  \n0      5.067315e-08  0.000000e+00  \n1      6.483798e-08  0.000000e+00  \n2      1.499339e-08  0.000000e+00  \n3      6.602901e-06  3.900000e-09  \n4      2.260505e-07  0.000000e+00  \n..              ...           ...  \n834    1.686392e-06  3.300000e-09  \n835    5.547362e-08  0.000000e+00  \n836    1.103470e-07  0.000000e+00  \n837    3.896998e-07  3.300000e-09  \n838    8.808865e-06  6.700000e-09  \n\n[839 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Synsets</th>\n      <th>domain_x</th>\n      <th>nrdirhypers_x</th>\n      <th>nrhypos_x</th>\n      <th>nrpartrels_normalised_x</th>\n      <th>depthfromtopsynset_normalised_x</th>\n      <th>glosslength_normalised_x</th>\n      <th>minwordlength_x</th>\n      <th>nroflemmas_x</th>\n      <th>polyscore_max_x</th>\n      <th>...</th>\n      <th>ngram_50y_max</th>\n      <th>ngram_100y_mean</th>\n      <th>ngram_100y_max</th>\n      <th>ngram_200y_mean</th>\n      <th>ngram_200y_max</th>\n      <th>ngram_400y_mean</th>\n      <th>ngram_400y_max</th>\n      <th>ngram_500y_mean</th>\n      <th>ngram_500y_max</th>\n      <th>bnc_100m_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Synset('adjustable_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.563173</td>\n      <td>17</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>5.067315e-08</td>\n      <td>2.252890e-08</td>\n      <td>5.067315e-08</td>\n      <td>1.380492e-08</td>\n      <td>5.067315e-08</td>\n      <td>6.919673e-09</td>\n      <td>5.067315e-08</td>\n      <td>5.336133e-09</td>\n      <td>5.067315e-08</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Synset('allen_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.391092</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>6.483798e-08</td>\n      <td>1.515313e-08</td>\n      <td>6.483798e-08</td>\n      <td>7.715051e-09</td>\n      <td>6.483798e-08</td>\n      <td>3.867145e-09</td>\n      <td>6.483798e-08</td>\n      <td>2.982164e-09</td>\n      <td>6.483798e-08</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Synset('alligator_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>1.517437</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>5.970550e-10</td>\n      <td>6.184165e-10</td>\n      <td>7.804026e-09</td>\n      <td>1.237592e-09</td>\n      <td>1.499339e-08</td>\n      <td>6.203393e-10</td>\n      <td>1.499339e-08</td>\n      <td>4.783770e-10</td>\n      <td>1.499339e-08</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Synset('awl.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15.7</td>\n      <td>0.911613</td>\n      <td>0.985552</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>3.752697e-07</td>\n      <td>3.562540e-07</td>\n      <td>6.002532e-07</td>\n      <td>5.869817e-07</td>\n      <td>2.510665e-06</td>\n      <td>6.210211e-07</td>\n      <td>6.602901e-06</td>\n      <td>5.069033e-07</td>\n      <td>6.602901e-06</td>\n      <td>3.900000e-09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Synset('backsaw.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.114194</td>\n      <td>1.110701</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2.446695e-08</td>\n      <td>1.704462e-08</td>\n      <td>2.446695e-08</td>\n      <td>1.451245e-08</td>\n      <td>3.507272e-08</td>\n      <td>9.018908e-09</td>\n      <td>2.260505e-07</td>\n      <td>6.954965e-09</td>\n      <td>2.260505e-07</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>834</th>\n      <td>Synset('ballet_skirt.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.947552</td>\n      <td>0.578283</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>8.004256e-07</td>\n      <td>2.485961e-07</td>\n      <td>8.004256e-07</td>\n      <td>1.531570e-07</td>\n      <td>8.004256e-07</td>\n      <td>1.136149e-07</td>\n      <td>8.004256e-07</td>\n      <td>9.223624e-08</td>\n      <td>1.686392e-06</td>\n      <td>3.300000e-09</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>Synset('mess_jacket.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>1.652238</td>\n      <td>11</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>8.272560e-09</td>\n      <td>1.233276e-08</td>\n      <td>2.136213e-08</td>\n      <td>1.358353e-08</td>\n      <td>5.083992e-08</td>\n      <td>6.963715e-09</td>\n      <td>5.547362e-08</td>\n      <td>5.370096e-09</td>\n      <td>5.547362e-08</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>836</th>\n      <td>Synset('long_johns.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.479149</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.103470e-07</td>\n      <td>2.680743e-08</td>\n      <td>1.103470e-07</td>\n      <td>1.393969e-08</td>\n      <td>1.103470e-07</td>\n      <td>6.987224e-09</td>\n      <td>1.103470e-07</td>\n      <td>5.388225e-09</td>\n      <td>1.103470e-07</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>837</th>\n      <td>Synset('undies.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>0.280880</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2.565946e-07</td>\n      <td>5.787213e-08</td>\n      <td>2.565946e-07</td>\n      <td>3.095668e-08</td>\n      <td>2.565946e-07</td>\n      <td>2.025520e-08</td>\n      <td>3.896998e-07</td>\n      <td>1.561987e-08</td>\n      <td>3.896998e-07</td>\n      <td>3.300000e-09</td>\n    </tr>\n    <tr>\n      <th>838</th>\n      <td>Synset('lingerie.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.561761</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.126403e-06</td>\n      <td>4.927242e-07</td>\n      <td>1.126403e-06</td>\n      <td>2.835355e-07</td>\n      <td>1.126403e-06</td>\n      <td>1.440483e-07</td>\n      <td>1.126403e-06</td>\n      <td>1.351753e-07</td>\n      <td>8.808865e-06</td>\n      <td>6.700000e-09</td>\n    </tr>\n  </tbody>\n</table>\n<p>839 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the pre-processed data all agreed\n",
    "google_ngrams_data = pd.read_csv('../Google_Ngrams/features_google_ngram.csv', index_col=None)\n",
    "bnc_data = pd.read_csv('../corpora_size/size_differential_features.csv', index_col=None)['bnc_100m_sum']/10000000000\n",
    "base_feature = ['nrdirhypers_x',\n",
    "                'nrhypos_x',\n",
    "                'nrpartrels_normalised_x',\n",
    "                'depthfromtopsynset_normalised_x',\n",
    "                'glosslength_normalised_x',\n",
    "                'minwordlength_x',\n",
    "                'nroflemmas_x',\n",
    "                'polyscore_max_x']\n",
    "\n",
    "target = ['vote_x']\n",
    "\n",
    "data = pd.concat([google_ngrams_data, bnc_data], axis=1)\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GlobalModel Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# split training set and testing set using K-Flod\n",
    "def new_features_global_model_test(dataset, feature, new_features, target):\n",
    "    K = 10\n",
    "    random_seed = 7 # R\n",
    "    data = dataset.reset_index()\n",
    "    if new_features is None:\n",
    "        feature_list = feature\n",
    "    else:\n",
    "        feature_list = feature + new_features\n",
    "    X = data[feature_list]\n",
    "    y = data[target]\n",
    "\n",
    "    K_Flod = StratifiedKFold(n_splits=K, shuffle=True, random_state=random_seed)\n",
    "    K_Flod.get_n_splits(X, y)\n",
    "    cohen_kappa = []\n",
    "    balanced_acc = []\n",
    "    for train_index, test_index in K_Flod.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # SMOTE algorithm\n",
    "        smote = SMOTE(random_state=random_seed, k_neighbors=2)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # define random forest model\n",
    "        rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "        # predict and make score\n",
    "        pipeline = make_pipeline(smote, rf)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "        cohen_kappa.append(kappa)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        balanced_acc.append(balanced_accuracy)\n",
    "\n",
    "    result_kappa = np.mean(cohen_kappa)\n",
    "    results_acc = np.mean(balanced_acc)\n",
    "\n",
    "    return result_kappa, results_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.7144327457398147, 0.8646313885119856)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features_global_model_test(data, base_feature, ['ngram_50y_max', 'ngram_100y_max', 'ngram_400y_mean', 'ngram_500y_max'], target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LocalModel Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# generate the local dataframe for different domains\n",
    "local_fruit = data.loc[data['domain_x']=='fruit']\n",
    "local_tool = data.loc[data['domain_x']=='tool']\n",
    "local_music = data.loc[data['domain_x']=='music']\n",
    "local_furniture = data.loc[data['domain_x']=='furn']\n",
    "local_garments = data.loc[data['domain_x']=='garm']\n",
    "\n",
    "local_list = [local_fruit, local_tool, local_music, local_furniture, local_garments]\n",
    "\n",
    "def new_feature_local_model_test(dataset_list, base_feature, new_feature, target):\n",
    "    random_seed = 7 # R\n",
    "    K = 10\n",
    "    if new_feature is None:\n",
    "        feature_list = base_feature\n",
    "    else:\n",
    "        feature_list = base_feature + new_feature\n",
    "\n",
    "    local_kappa_list = []\n",
    "    local_balancedAcc_list = []\n",
    "    for dataset in dataset_list:\n",
    "        X = dataset[feature_list]\n",
    "        y = dataset[target]\n",
    "        K_Flod = StratifiedKFold(n_splits=K, shuffle=True, random_state=random_seed)\n",
    "        K_Flod.get_n_splits(X, y)\n",
    "        cohen_kappa = []\n",
    "        balanced_acc = []\n",
    "        for train_index, test_index in K_Flod.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # SMOTE algorithm\n",
    "            smote = SMOTE(random_state=random_seed, k_neighbors=2)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "            # define random forest model\n",
    "            rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "            # predict and make score\n",
    "            pipeline = make_pipeline(smote, rf)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "\n",
    "            kappa = cohen_kappa_score(y_test, y_pred)\n",
    "            cohen_kappa.append(kappa)\n",
    "            balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "            balanced_acc.append(balanced_accuracy)\n",
    "\n",
    "        cohen_kappa_mean = np.mean(cohen_kappa)\n",
    "        balanced_acc_mean = np.mean(balanced_acc)\n",
    "        local_kappa_list.append(cohen_kappa_mean)\n",
    "        local_balancedAcc_list.append(balanced_acc_mean)\n",
    "\n",
    "    local_kappa = np.mean(local_kappa_list)\n",
    "    local_acc = np.mean(local_balancedAcc_list)\n",
    "\n",
    "    return local_kappa, local_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.7115015229441634, 0.8622309651133181)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_local_model_test(local_list, base_feature, ['ngram_100y_max', 'ngram_400y_mean'], target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TransferModel Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": "# generate the local dataframe for different domains\nlocal_fruit = data.loc[data['domain_x']=='fruit']\nlocal_tool = data.loc[data['domain_x']=='tool']\nlocal_music = data.loc[data['domain_x']=='music']\nlocal_furniture = data.loc[data['domain_x']=='furn']\nlocal_garments = data.loc[data['domain_x']=='garm']\n\nlocal_list = [local_fruit, local_tool, local_music, local_furniture, local_garments]\n\n# generate the unseen(transfer) dataframe for different domains\nunseen_fruit = data.loc[data['domain_x']!='fruit']\nunseen_tool = data.loc[data['domain_x']!='tool']\nunseen_music = data.loc[data['domain_x']!='music']\nunseen_furniture = data.loc[data['domain_x']!='furn']\nunseen_garments = data.loc[data['domain_x']!='garm']\n\nunseen_list = [unseen_fruit, unseen_tool, unseen_music, unseen_furniture, unseen_garments]\n\ndef new_feature_transfer_model_test(train_list, test_list, base_feature, new_feature, target):\n    random_seed = 7 # R\n    transfer_kappa_list = []\n    transfer_balancedAcc_list = []\n    for counter in range(len(train_list)):\n        training_data = train_list[counter].reset_index()\n        testing_data = test_list[counter].reset_index()\n        if new_feature is None:\n            feature_list = base_feature\n        else:\n            feature_list = base_feature + new_feature\n        X_train = training_data[feature_list]\n        y_train = training_data[target]\n        X_test = testing_data[feature_list]\n        y_test = testing_data[target]\n\n        # SMOTE algorithm\n        smote = SMOTE(random_state=random_seed, k_neighbors=2)\n        X_train, y_train = smote.fit_resample(X_train, y_train)\n\n        # define random forest model\n        rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n\n        # predict and make score\n        pipeline = make_pipeline(smote, rf)\n        y_pred = pipeline.predict(X_test)\n\n        kappa = cohen_kappa_score(y_test, y_pred)\n        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n\n        transfer_kappa_list.append(kappa)\n        transfer_balancedAcc_list.append(balanced_accuracy)\n\n    transfer_kappa = np.mean(transfer_kappa_list), np.mean(transfer_balancedAcc_list)\n\n\n    return transfer_kappa",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.5779510418076527, 0.824327867292346)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "new_feature_transfer_model_test(unseen_list, local_list, base_feature, ['ngram_5y_mean', 'ngram_50y_mean', 'ngram_100y_mean', 'ngram_200y_max', 'ngram_500y_max'], target)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}