{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score, balanced_accuracy_score\n",
    "from itertools import combinations\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                              Synsets domain_x  nrdirhypers_x  nrhypos_x  \\\n0    Synset('adjustable_wrench.n.01')     tool              1          7   \n1         Synset('allen_wrench.n.01')     tool              1          0   \n2     Synset('alligator_wrench.n.01')     tool              1          0   \n3                  Synset('awl.n.01')     tool              1          2   \n4              Synset('backsaw.n.01')     tool              1          0   \n..                                ...      ...            ...        ...   \n771       Synset('ballet_skirt.n.01')     garm              1          0   \n772        Synset('mess_jacket.n.01')     garm              1          0   \n773         Synset('long_johns.n.01')     garm              1          0   \n774             Synset('undies.n.01')     garm              1          0   \n775           Synset('lingerie.n.01')     garm              1          2   \n\n     nrpartrels_normalised_x  depthfromtopsynset_normalised_x  \\\n0                        0.0                         1.012903   \n1                        0.0                         1.012903   \n2                        0.0                         1.012903   \n3                       15.7                         0.911613   \n4                        0.0                         1.114194   \n..                       ...                              ...   \n771                      0.0                         0.947552   \n772                      0.0                         1.158120   \n773                      0.0                         1.052836   \n774                      0.0                         1.158120   \n775                      0.0                         1.052836   \n\n     glosslength_normalised_x  minwordlength_x  nroflemmas_x  polyscore_max_x  \\\n0                    0.563173               17             2                1   \n1                    0.391092               12             1                1   \n2                    1.517437               16             1                1   \n3                    0.985552                3             1                1   \n4                    1.110701                7             2                1   \n..                        ...              ...           ...              ...   \n771                  0.578283                4             2                2   \n772                  1.652238               11             3                1   \n773                  0.479149               10             1                1   \n774                  0.280880                6             1                1   \n775                  0.561761                8             2                1   \n\n     ... vec_291  vec_292  vec_293  vec_294  vec_295  vec_296  vec_297  \\\n0    ...  0.0146  -0.0488   0.0469  -0.0441   0.0290   0.0741  -0.0575   \n1    ...  0.0211  -0.0197   0.0557  -0.0591  -0.0069   0.0317  -0.0198   \n2    ...  0.0185  -0.0215   0.0354  -0.0740   0.0203   0.0379  -0.0331   \n3    ...  0.0543  -0.0515  -0.0017  -0.0101   0.0345   0.1180   0.0885   \n4    ... -0.0457  -0.0741   0.0207  -0.0395   0.0297  -0.0542  -0.1040   \n..   ...     ...      ...      ...      ...      ...      ...      ...   \n771  ...  0.0215  -0.0879   0.0333  -0.0301  -0.0218  -0.0342   0.0383   \n772  ...  0.0092  -0.0397  -0.0152  -0.0135  -0.0304   0.0031  -0.0402   \n773  ... -0.0458  -0.0743   0.0254  -0.0212  -0.0433  -0.0129   0.0235   \n774  ... -0.0686  -0.0497   0.0083  -0.0549  -0.0501   0.0107   0.0060   \n775  ... -0.0619   0.0217   0.0249  -0.0384  -0.0286   0.0330   0.0205   \n\n     vec_298  vec_299   dis_c_d  \n0    -0.0075  -0.0259  0.484202  \n1    -0.0043  -0.0739  0.549829  \n2    -0.0180  -0.0362  0.431030  \n3    -0.0592   0.0560  0.327994  \n4    -0.0326   0.0052  0.362438  \n..       ...      ...       ...  \n771   0.0045  -0.0346  0.263475  \n772  -0.0054  -0.0153  0.572053  \n773  -0.0929   0.0031  0.464427  \n774  -0.0205   0.0133  0.501280  \n775   0.0371  -0.0025  0.521421  \n\n[776 rows x 331 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Synsets</th>\n      <th>domain_x</th>\n      <th>nrdirhypers_x</th>\n      <th>nrhypos_x</th>\n      <th>nrpartrels_normalised_x</th>\n      <th>depthfromtopsynset_normalised_x</th>\n      <th>glosslength_normalised_x</th>\n      <th>minwordlength_x</th>\n      <th>nroflemmas_x</th>\n      <th>polyscore_max_x</th>\n      <th>...</th>\n      <th>vec_291</th>\n      <th>vec_292</th>\n      <th>vec_293</th>\n      <th>vec_294</th>\n      <th>vec_295</th>\n      <th>vec_296</th>\n      <th>vec_297</th>\n      <th>vec_298</th>\n      <th>vec_299</th>\n      <th>dis_c_d</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Synset('adjustable_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.563173</td>\n      <td>17</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0146</td>\n      <td>-0.0488</td>\n      <td>0.0469</td>\n      <td>-0.0441</td>\n      <td>0.0290</td>\n      <td>0.0741</td>\n      <td>-0.0575</td>\n      <td>-0.0075</td>\n      <td>-0.0259</td>\n      <td>0.484202</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Synset('allen_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.391092</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0211</td>\n      <td>-0.0197</td>\n      <td>0.0557</td>\n      <td>-0.0591</td>\n      <td>-0.0069</td>\n      <td>0.0317</td>\n      <td>-0.0198</td>\n      <td>-0.0043</td>\n      <td>-0.0739</td>\n      <td>0.549829</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Synset('alligator_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>1.517437</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0185</td>\n      <td>-0.0215</td>\n      <td>0.0354</td>\n      <td>-0.0740</td>\n      <td>0.0203</td>\n      <td>0.0379</td>\n      <td>-0.0331</td>\n      <td>-0.0180</td>\n      <td>-0.0362</td>\n      <td>0.431030</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Synset('awl.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15.7</td>\n      <td>0.911613</td>\n      <td>0.985552</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0543</td>\n      <td>-0.0515</td>\n      <td>-0.0017</td>\n      <td>-0.0101</td>\n      <td>0.0345</td>\n      <td>0.1180</td>\n      <td>0.0885</td>\n      <td>-0.0592</td>\n      <td>0.0560</td>\n      <td>0.327994</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Synset('backsaw.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.114194</td>\n      <td>1.110701</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.0457</td>\n      <td>-0.0741</td>\n      <td>0.0207</td>\n      <td>-0.0395</td>\n      <td>0.0297</td>\n      <td>-0.0542</td>\n      <td>-0.1040</td>\n      <td>-0.0326</td>\n      <td>0.0052</td>\n      <td>0.362438</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>771</th>\n      <td>Synset('ballet_skirt.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.947552</td>\n      <td>0.578283</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.0215</td>\n      <td>-0.0879</td>\n      <td>0.0333</td>\n      <td>-0.0301</td>\n      <td>-0.0218</td>\n      <td>-0.0342</td>\n      <td>0.0383</td>\n      <td>0.0045</td>\n      <td>-0.0346</td>\n      <td>0.263475</td>\n    </tr>\n    <tr>\n      <th>772</th>\n      <td>Synset('mess_jacket.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>1.652238</td>\n      <td>11</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0092</td>\n      <td>-0.0397</td>\n      <td>-0.0152</td>\n      <td>-0.0135</td>\n      <td>-0.0304</td>\n      <td>0.0031</td>\n      <td>-0.0402</td>\n      <td>-0.0054</td>\n      <td>-0.0153</td>\n      <td>0.572053</td>\n    </tr>\n    <tr>\n      <th>773</th>\n      <td>Synset('long_johns.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.479149</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.0458</td>\n      <td>-0.0743</td>\n      <td>0.0254</td>\n      <td>-0.0212</td>\n      <td>-0.0433</td>\n      <td>-0.0129</td>\n      <td>0.0235</td>\n      <td>-0.0929</td>\n      <td>0.0031</td>\n      <td>0.464427</td>\n    </tr>\n    <tr>\n      <th>774</th>\n      <td>Synset('undies.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>0.280880</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.0686</td>\n      <td>-0.0497</td>\n      <td>0.0083</td>\n      <td>-0.0549</td>\n      <td>-0.0501</td>\n      <td>0.0107</td>\n      <td>0.0060</td>\n      <td>-0.0205</td>\n      <td>0.0133</td>\n      <td>0.501280</td>\n    </tr>\n    <tr>\n      <th>775</th>\n      <td>Synset('lingerie.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.561761</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.0619</td>\n      <td>0.0217</td>\n      <td>0.0249</td>\n      <td>-0.0384</td>\n      <td>-0.0286</td>\n      <td>0.0330</td>\n      <td>0.0205</td>\n      <td>0.0371</td>\n      <td>-0.0025</td>\n      <td>0.521421</td>\n    </tr>\n  </tbody>\n</table>\n<p>776 rows × 331 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_data = pd.read_csv('../Word2Vec/w2v_eli.csv', index_col=None)\n",
    "base_feature = ['nrdirhypers_x',\n",
    "                'nrhypos_x',\n",
    "                'nrpartrels_normalised_x',\n",
    "                'depthfromtopsynset_normalised_x',\n",
    "                'glosslength_normalised_x',\n",
    "                'minwordlength_x',\n",
    "                'nroflemmas_x',\n",
    "                'polyscore_max_x']\n",
    "target = ['vote_x']\n",
    "\n",
    "w2v_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmark: Random Forest: W2V distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "## GlobalModel Test",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": "# split training set and testing set using K-Flod\ndef global_model_test(dataset, feature, synthetics, target):\n    K = 10\n    random_seed = 7 # R\n    data = dataset.reset_index()\n    feature_list = feature + synthetics\n    X = data[feature_list]\n    y = data[target]\n\n    K_Flod = StratifiedKFold(n_splits=K, shuffle=True, random_state=random_seed)\n    K_Flod.get_n_splits(X, y)\n    cohen_kappa = []\n    balanced_acc = []\n    for train_index, test_index in K_Flod.split(X, y):\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n        # SMOTE algorithm\n        smote = SMOTE(random_state=random_seed, k_neighbors=2)\n        X_train, y_train = smote.fit_resample(X_train, y_train)\n\n        # define random forest model\n        rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n\n        # predict and make score\n        pipeline = make_pipeline(smote, rf)\n        y_pred = pipeline.predict(X_test)\n\n        kappa = cohen_kappa_score(y_test, y_pred)\n        cohen_kappa.append(kappa)\n        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n        balanced_acc.append(balanced_accuracy)\n\n    results = []\n\n    results.append(np.mean(cohen_kappa))\n    results.append(np.mean(balanced_acc))\n\n    return results",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.7044099768267154, 0.8565662166505946]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "global_model_test(w2v_data, base_feature, ['ngram_50y_max', 'ngram_100y_max', 'ngram_400y_mean', 'ngram_500y_max', 'dis_c_d'], target)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "## LocalModel Test",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": "# generate the local dataframe for different domains\nlocal_fruit = w2v_data.loc[w2v_data['domain_x']=='fruit']\nlocal_tool = w2v_data.loc[w2v_data['domain_x']=='tool']\nlocal_music = w2v_data.loc[w2v_data['domain_x']=='music']\nlocal_furniture = w2v_data.loc[w2v_data['domain_x']=='furn']\nlocal_garments = w2v_data.loc[w2v_data['domain_x']=='garm']\n\nlocal_list = [local_fruit, local_tool, local_music, local_furniture, local_garments]\n\ndef local_model_test(dataset_list, base_feature, synthetics, target):\n    random_seed = 7 # R\n    K = 10\n    feature_list = base_feature + synthetics\n\n    local_kappa_list = []\n    local_balancedAcc_list = []\n    for dataset in dataset_list:\n        X = dataset[feature_list]\n        y = dataset[target]\n        K_Flod = StratifiedKFold(n_splits=K, shuffle=True, random_state=random_seed)\n        K_Flod.get_n_splits(X, y)\n        cohen_kappa = []\n        balanced_acc = []\n        for train_index, test_index in K_Flod.split(X, y):\n            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n            # SMOTE algorithm\n            smote = SMOTE(random_state=random_seed, k_neighbors=2)\n            X_train, y_train = smote.fit_resample(X_train, y_train)\n\n            # define random forest model\n            rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n\n            # predict and make score\n            pipeline = make_pipeline(smote, rf)\n            y_pred = pipeline.predict(X_test)\n\n            kappa = cohen_kappa_score(y_test, y_pred)\n            cohen_kappa.append(kappa)\n            balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n            balanced_acc.append(balanced_accuracy)\n\n        cohen_kappa_mean = np.mean(cohen_kappa)\n        balanced_acc_mean = np.mean(balanced_acc)\n        local_kappa_list.append(cohen_kappa_mean)\n        local_balancedAcc_list.append(balanced_acc_mean)\n\n    local_kappa = np.mean(local_kappa_list)\n    local_acc = np.mean(local_balancedAcc_list)\n\n    return local_kappa, local_acc",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.7061741962510757, 0.8557261904761907)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "local_model_test(local_list, base_feature, ['ngram_100y_max', 'ngram_400y_mean', 'dis_c_d'], target)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "## TransferModel Test",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": "# generate the local dataframe for different domains\nlocal_fruit = w2v_data.loc[w2v_data['domain_x']=='fruit']\nlocal_tool = w2v_data.loc[w2v_data['domain_x']=='tool']\nlocal_music = w2v_data.loc[w2v_data['domain_x']=='music']\nlocal_furniture = w2v_data.loc[w2v_data['domain_x']=='furn']\nlocal_garments = w2v_data.loc[w2v_data['domain_x']=='garm']\n\nlocal_list = [local_fruit, local_tool, local_music, local_furniture, local_garments]\n\n# generate the unseen(transfer) dataframe for different domains\nunseen_fruit = w2v_data.loc[w2v_data['domain_x']!='fruit']\nunseen_tool = w2v_data.loc[w2v_data['domain_x']!='tool']\nunseen_music = w2v_data.loc[w2v_data['domain_x']!='music']\nunseen_furniture = w2v_data.loc[w2v_data['domain_x']!='furn']\nunseen_garments = w2v_data.loc[w2v_data['domain_x']!='garm']\n\nunseen_list = [unseen_fruit, unseen_tool, unseen_music, unseen_furniture, unseen_garments]\n\ndef transfer_model_test(train_list, test_list, base_feature, synthetics, target):\n    random_seed = 7 # R\n    transfer_kappa_list = []\n    transfer_balancedAcc_list = []\n    for counter in range(len(train_list)):\n        training_data = train_list[counter].reset_index()\n        testing_data = test_list[counter].reset_index()\n        feature_list = base_feature + synthetics\n        X_train = training_data[feature_list]\n        y_train = training_data[target]\n        X_test = testing_data[feature_list]\n        y_test = testing_data[target]\n\n        # SMOTE algorithm\n        smote = SMOTE(random_state=random_seed, k_neighbors=2)\n        X_train, y_train = smote.fit_resample(X_train, y_train)\n\n        # define random forest model\n        rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n\n        # predict and make score\n        pipeline = make_pipeline(smote, rf)\n        y_pred = pipeline.predict(X_test)\n\n        kappa = cohen_kappa_score(y_test, y_pred)\n        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n\n        transfer_kappa_list.append(kappa)\n        transfer_balancedAcc_list.append(balanced_accuracy)\n\n    transfer_kappa = np.mean(transfer_kappa_list), np.mean(transfer_balancedAcc_list)\n\n\n    return transfer_kappa",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "source": "transfer_model_test(unseen_list, local_list, base_feature, ['ngram_5y_mean', 'ngram_50y_mean', 'ngram_100y_mean', 'ngram_200y_max', 'ngram_500y_max', 'dis_c_d'], target)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.5722599214246016, 0.8206065936685037)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}