{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score, balanced_accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# read the pre-processed data all agreed\n",
    "data = pd.read_csv('./size_differential_features.csv', index_col=0)\n",
    "\n",
    "# generate the local dataframe for different domains\n",
    "local_fruit = data.loc[data['domain_x']=='fruit'].reset_index()\n",
    "local_tool = data.loc[data['domain_x']=='tool'].reset_index()\n",
    "local_music = data.loc[data['domain_x']=='music'].reset_index()\n",
    "local_furniture = data.loc[data['domain_x']=='furn'].reset_index()\n",
    "local_garments = data.loc[data['domain_x']=='garm'].reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# define features and target\n",
    "features = ['ngrams_last_mean',\n",
    "            'nrdirhypers_x',\n",
    "            'nrhypos_x',\n",
    "            'nrpartrels_normalised_x',\n",
    "            'depthfromtopsynset_normalised_x',\n",
    "            'glosslength_normalised_x',\n",
    "            'minwordlength_x',\n",
    "            'nroflemmas_x',\n",
    "            'polyscore_max_x']\n",
    "target = ['vote_x'] # nb / b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# split training set and testing set using K-Flod\n",
    "def global_model_test(dataset, feature, sized_corpora, target):\n",
    "    K = 10\n",
    "    random_seed = 7 # R\n",
    "    data = dataset.reset_index()\n",
    "    feature_list = feature + [sized_corpora]\n",
    "    X = data[feature_list]\n",
    "    y = data[target]\n",
    "\n",
    "    K_Flod = StratifiedKFold(n_splits=K, shuffle=True, random_state=random_seed)\n",
    "    K_Flod.get_n_splits(X, y)\n",
    "    cohen_kappa = []\n",
    "    balanced_acc = []\n",
    "    for train_index, test_index in K_Flod.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # SMOTE algorithm\n",
    "        smote = SMOTE(random_state=random_seed, k_neighbors=2)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # define random forest model\n",
    "        rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "        # predict and make score\n",
    "        pipeline = make_pipeline(smote, rf)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "        cohen_kappa.append(kappa)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        balanced_acc.append(balanced_accuracy)\n",
    "\n",
    "    results = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results = pd.DataFrame(results).transpose()\n",
    "\n",
    "    results['cohen kappa / 10'] = np.mean(cohen_kappa)\n",
    "    results['balanced acc / 10'] = np.mean(balanced_acc)\n",
    "    results['global'] = 5\n",
    "\n",
    "    # importance of features\n",
    "    importance = rf.feature_importances_\n",
    "    importance = pd.DataFrame([features, importance]).transpose()\n",
    "    importance = importance.rename(columns={0:'feature', 1:'importance'}).sort_values('importance', ascending=False)\n",
    "\n",
    "    return results, importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KBNC: 1 million"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sized_corpora = 'kbnc_1m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.823529  0.823529  0.823529  17.000000          0.691517   \n nb             0.954545  0.954545  0.954545  66.000000          0.691517   \n accuracy       0.927711  0.927711  0.927711   0.927711          0.691517   \n macro avg      0.889037  0.889037  0.889037  83.000000          0.691517   \n weighted avg   0.927711  0.927711  0.927711  83.000000          0.691517   \n \n               balanced acc / 10  global  \n b                       0.85023       5  \n nb                      0.85023       5  \n accuracy                0.85023       5  \n macro avg               0.85023       5  \n weighted avg            0.85023       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.370331\n 5         glosslength_normalised_x   0.137375\n 0                 ngrams_last_mean   0.133441\n 6                  minwordlength_x   0.109875\n 3          nrpartrels_normalised_x   0.103399\n 2                        nrhypos_x   0.048189\n 9                              NaN   0.035055\n 8                  polyscore_max_x   0.033016\n 7                     nroflemmas_x   0.027104\n 1                    nrdirhypers_x   0.002215)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CABNC: 1 million, 2.4 million"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.736842  0.823529  0.777778  17.000000          0.685486   \n nb             0.953125  0.924242  0.938462  66.000000          0.685486   \n accuracy       0.903614  0.903614  0.903614   0.903614          0.685486   \n macro avg      0.844984  0.873886  0.858120  83.000000          0.685486   \n weighted avg   0.908826  0.903614  0.905550  83.000000          0.685486   \n \n               balanced acc / 10  global  \n b                      0.851834       5  \n nb                     0.851834       5  \n accuracy               0.851834       5  \n macro avg              0.851834       5  \n weighted avg           0.851834       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.373534\n 5         glosslength_normalised_x   0.138268\n 0                 ngrams_last_mean   0.133284\n 3          nrpartrels_normalised_x   0.106026\n 6                  minwordlength_x   0.105199\n 2                        nrhypos_x   0.045716\n 8                  polyscore_max_x   0.038181\n 9                              NaN    0.03012\n 7                     nroflemmas_x   0.027354\n 1                    nrdirhypers_x   0.002319)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'cabnc_per_100k_1m'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.789474  0.882353  0.833333  17.000000          0.699077   \n nb             0.968750  0.939394  0.953846  66.000000          0.699077   \n accuracy       0.927711  0.927711  0.927711   0.927711          0.699077   \n macro avg      0.879112  0.910873  0.893590  83.000000          0.699077   \n weighted avg   0.932031  0.927711  0.929163  83.000000          0.699077   \n \n               balanced acc / 10  global  \n b                      0.853742       5  \n nb                     0.853742       5  \n accuracy               0.853742       5  \n macro avg              0.853742       5  \n weighted avg           0.853742       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.370363\n 5         glosslength_normalised_x   0.149594\n 0                 ngrams_last_mean   0.130475\n 6                  minwordlength_x   0.106714\n 3          nrpartrels_normalised_x   0.101262\n 2                        nrhypos_x   0.041208\n 8                  polyscore_max_x   0.037968\n 9                              NaN   0.034192\n 7                     nroflemmas_x   0.025792\n 1                    nrdirhypers_x   0.002432)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'cabnc_per_100k_2_4m'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CHILDES: 5.7 million, 2.4 million, 1 million"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.842105  0.941176  0.888889  17.000000          0.685825   \n nb             0.984375  0.954545  0.969231  66.000000          0.685825   \n accuracy       0.951807  0.951807  0.951807   0.951807          0.685825   \n macro avg      0.913240  0.947861  0.929060  83.000000          0.685825   \n weighted avg   0.955235  0.951807  0.952775  83.000000          0.685825   \n \n               balanced acc / 10  global  \n b                      0.854018       5  \n nb                     0.854018       5  \n accuracy               0.854018       5  \n macro avg              0.854018       5  \n weighted avg           0.854018       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.363085\n 5         glosslength_normalised_x   0.133649\n 0                 ngrams_last_mean   0.123163\n 6                  minwordlength_x   0.106142\n 3          nrpartrels_normalised_x   0.082547\n 9                              NaN   0.082235\n 2                        nrhypos_x   0.042607\n 8                  polyscore_max_x   0.036329\n 7                     nroflemmas_x    0.02778\n 1                    nrdirhypers_x   0.002464)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'childes_1m_rel_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.842105  0.941176  0.888889  17.000000          0.683559   \n nb             0.984375  0.954545  0.969231  66.000000          0.683559   \n accuracy       0.951807  0.951807  0.951807   0.951807          0.683559   \n macro avg      0.913240  0.947861  0.929060  83.000000          0.683559   \n weighted avg   0.955235  0.951807  0.952775  83.000000          0.683559   \n \n               balanced acc / 10  global  \n b                      0.853283       5  \n nb                     0.853283       5  \n accuracy               0.853283       5  \n macro avg              0.853283       5  \n weighted avg           0.853283       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.367108\n 5         glosslength_normalised_x    0.13707\n 0                 ngrams_last_mean   0.128761\n 6                  minwordlength_x   0.108701\n 3          nrpartrels_normalised_x   0.082473\n 9                              NaN   0.063981\n 2                        nrhypos_x    0.04306\n 8                  polyscore_max_x   0.038121\n 7                     nroflemmas_x    0.02821\n 1                    nrdirhypers_x   0.002514)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'childes_2_4m_rel_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.833333  0.882353  0.857143  17.000000          0.660334   \n nb             0.969231  0.954545  0.961832  66.000000          0.660334   \n accuracy       0.939759  0.939759  0.939759   0.939759          0.660334   \n macro avg      0.901282  0.918449  0.909487  83.000000          0.660334   \n weighted avg   0.941396  0.939759  0.940390  83.000000          0.660334   \n \n               balanced acc / 10  global  \n b                      0.840341       5  \n nb                     0.840341       5  \n accuracy               0.840341       5  \n macro avg              0.840341       5  \n weighted avg           0.840341       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.364524\n 5         glosslength_normalised_x   0.136819\n 0                 ngrams_last_mean   0.131156\n 6                  minwordlength_x    0.11026\n 3          nrpartrels_normalised_x    0.08298\n 9                              NaN   0.064169\n 2                        nrhypos_x   0.042456\n 8                  polyscore_max_x   0.037328\n 7                     nroflemmas_x   0.027864\n 1                    nrdirhypers_x   0.002445)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'childes_5_7m_rel_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BNC: 100 million, 5.7 million, 2.4 million, 1 million"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.800000  0.941176  0.864865  17.000000          0.698233   \n nb             0.984127  0.939394  0.961240  66.000000          0.698233   \n accuracy       0.939759  0.939759  0.939759   0.939759          0.698233   \n macro avg      0.892063  0.940285  0.913053  83.000000          0.698233   \n weighted avg   0.946414  0.939759  0.941501  83.000000          0.698233   \n \n               balanced acc / 10  global  \n b                      0.853742       5  \n nb                     0.853742       5  \n accuracy               0.853742       5  \n macro avg              0.853742       5  \n weighted avg           0.853742       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.368128\n 5         glosslength_normalised_x   0.138929\n 0                 ngrams_last_mean   0.129226\n 3          nrpartrels_normalised_x   0.109587\n 6                  minwordlength_x    0.10661\n 2                        nrhypos_x   0.043291\n 9                              NaN   0.039832\n 8                  polyscore_max_x   0.033136\n 7                     nroflemmas_x   0.029014\n 1                    nrdirhypers_x   0.002247)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'bnc_1m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.789474  0.882353  0.833333  17.000000          0.709009   \n nb             0.968750  0.939394  0.953846  66.000000          0.709009   \n accuracy       0.927711  0.927711  0.927711   0.927711          0.709009   \n macro avg      0.879112  0.910873  0.893590  83.000000          0.709009   \n weighted avg   0.932031  0.927711  0.929163  83.000000          0.709009   \n \n               balanced acc / 10  global  \n b                      0.860044       5  \n nb                     0.860044       5  \n accuracy               0.860044       5  \n macro avg              0.860044       5  \n weighted avg           0.860044       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.359973\n 5         glosslength_normalised_x   0.141079\n 0                 ngrams_last_mean   0.126889\n 3          nrpartrels_normalised_x    0.11451\n 6                  minwordlength_x   0.102736\n 9                              NaN   0.046835\n 2                        nrhypos_x   0.044841\n 8                  polyscore_max_x   0.032984\n 7                     nroflemmas_x   0.028021\n 1                    nrdirhypers_x   0.002132)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'bnc_2_4m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.888889  0.941176  0.914286  17.000000          0.712823   \n nb             0.984615  0.969697  0.977099  66.000000          0.712823   \n accuracy       0.963855  0.963855  0.963855   0.963855          0.712823   \n macro avg      0.936752  0.955437  0.945692  83.000000          0.712823   \n weighted avg   0.965009  0.963855  0.964234  83.000000          0.712823   \n \n               balanced acc / 10  global  \n b                      0.860965       5  \n nb                     0.860965       5  \n accuracy               0.860965       5  \n macro avg              0.860965       5  \n weighted avg           0.860965       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.356451\n 5         glosslength_normalised_x   0.132684\n 0                 ngrams_last_mean   0.128223\n 3          nrpartrels_normalised_x   0.117791\n 6                  minwordlength_x   0.102111\n 9                              NaN   0.056655\n 2                        nrhypos_x   0.044823\n 8                  polyscore_max_x   0.032861\n 7                     nroflemmas_x   0.026702\n 1                    nrdirhypers_x   0.001698)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'bnc_5_7m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.842105  0.941176  0.888889  17.000000          0.714009   \n nb             0.984375  0.954545  0.969231  66.000000          0.714009   \n accuracy       0.951807  0.951807  0.951807   0.951807          0.714009   \n macro avg      0.913240  0.947861  0.929060  83.000000          0.714009   \n weighted avg   0.955235  0.951807  0.952775  83.000000          0.714009   \n \n               balanced acc / 10  global  \n b                      0.859528       5  \n nb                     0.859528       5  \n accuracy               0.859528       5  \n macro avg              0.859528       5  \n weighted avg           0.859528       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.340294\n 3          nrpartrels_normalised_x   0.141376\n 5         glosslength_normalised_x   0.125519\n 0                 ngrams_last_mean   0.117697\n 6                  minwordlength_x   0.094382\n 9                              NaN   0.081304\n 2                        nrhypos_x   0.045248\n 8                  polyscore_max_x   0.027948\n 7                     nroflemmas_x   0.024461\n 1                    nrdirhypers_x   0.001771)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'bnc_100m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}