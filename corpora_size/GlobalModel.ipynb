{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score, balanced_accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            Synsets domain_x  \\\nnorm                                                           \nadjustable_wrench  Synset('adjustable_wrench.n.01')     tool   \nallen_wrench            Synset('allen_wrench.n.01')     tool   \nalligator_wrench    Synset('alligator_wrench.n.01')     tool   \nawl                              Synset('awl.n.01')     tool   \nbacksaw                      Synset('backsaw.n.01')     tool   \n...                                             ...      ...   \nballet_skirt            Synset('ballet_skirt.n.01')     garm   \nmess_jacket              Synset('mess_jacket.n.01')     garm   \nlong_johns                Synset('long_johns.n.01')     garm   \nundies                        Synset('undies.n.01')     garm   \nlingerie                    Synset('lingerie.n.01')     garm   \n\n                   ngrams_last_mean  nrdirhypers_x  nrhypos_x  \\\nnorm                                                            \nadjustable_wrench        -18.854402              1          7   \nallen_wrench             -18.389126              1          0   \nalligator_wrench         -22.354690              1          0   \nawl                      -14.809997              1          2   \nbacksaw                  -18.327476              1          0   \n...                             ...            ...        ...   \nballet_skirt             -16.872435              1          0   \nmess_jacket              -18.743772              1          0   \nlong_johns               -16.882419              1          0   \nundies                   -16.330160              1          0   \nlingerie                 -15.203406              1          2   \n\n                   nrpartrels_normalised_x  depthfromtopsynset_normalised_x  \\\nnorm                                                                          \nadjustable_wrench                      0.0                         1.012903   \nallen_wrench                           0.0                         1.012903   \nalligator_wrench                       0.0                         1.012903   \nawl                                   15.7                         0.911613   \nbacksaw                                0.0                         1.114194   \n...                                    ...                              ...   \nballet_skirt                           0.0                         0.947552   \nmess_jacket                            0.0                         1.158120   \nlong_johns                             0.0                         1.052836   \nundies                                 0.0                         1.158120   \nlingerie                               0.0                         1.052836   \n\n                   glosslength_normalised_x  minwordlength_x  nroflemmas_x  \\\nnorm                                                                         \nadjustable_wrench                  0.563173               17             2   \nallen_wrench                       0.391092               12             1   \nalligator_wrench                   1.517437               16             1   \nawl                                0.985552                3             1   \nbacksaw                            1.110701                7             2   \n...                                     ...              ...           ...   \nballet_skirt                       0.578283                4             2   \nmess_jacket                        1.652238               11             3   \nlong_johns                         0.479149               10             1   \nundies                             0.280880                6             1   \nlingerie                           0.561761                8             2   \n\n                   ...  kbnc_1m_sum childes_1m_rel_sum  childes_2_4m_rel_sum  \\\nnorm               ...                                                         \nadjustable_wrench  ...            0                0.0                   0.0   \nallen_wrench       ...            0                0.0                   0.0   \nalligator_wrench   ...            0                0.0                   0.0   \nawl                ...            0                0.0                   0.0   \nbacksaw            ...            0                0.0                   0.0   \n...                ...          ...                ...                   ...   \nballet_skirt       ...            0                0.0                   0.0   \nmess_jacket        ...            0                0.0                   0.0   \nlong_johns         ...            0                0.0                   0.0   \nundies             ...            0                0.0                   0.0   \nlingerie           ...            0                0.0                   0.0   \n\n                   childes_5_7m_rel_sum  bnc_1m_sum  bnc_5_7m_sum  \\\nnorm                                                                \nadjustable_wrench          0.000000e+00           0             0   \nallen_wrench               0.000000e+00           0             0   \nalligator_wrench           0.000000e+00           0             0   \nawl                        0.000000e+00           1             3   \nbacksaw                    0.000000e+00           0             0   \n...                                 ...         ...           ...   \nballet_skirt               1.754386e-07           0             0   \nmess_jacket                0.000000e+00           0             0   \nlong_johns                 0.000000e+00           0             0   \nundies                     0.000000e+00           1             1   \nlingerie                   0.000000e+00           1             1   \n\n                   bnc_2_4m_sum  bnc_100m_sum  cabnc_per_100k_2_4m  \\\nnorm                                                                 \nadjustable_wrench             0             0                    0   \nallen_wrench                  0             0                    0   \nalligator_wrench              0             0                    0   \nawl                           1            39                    0   \nbacksaw                       0             0                    0   \n...                         ...           ...                  ...   \nballet_skirt                  0            33                    0   \nmess_jacket                   0             0                    0   \nlong_johns                    0             0                    0   \nundies                        1            33                    0   \nlingerie                      1            67                    0   \n\n                   cabnc_per_100k_1m  \nnorm                                  \nadjustable_wrench                  0  \nallen_wrench                       0  \nalligator_wrench                   0  \nawl                                0  \nbacksaw                            0  \n...                              ...  \nballet_skirt                       0  \nmess_jacket                        0  \nlong_johns                         0  \nundies                             0  \nlingerie                           0  \n\n[839 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Synsets</th>\n      <th>domain_x</th>\n      <th>ngrams_last_mean</th>\n      <th>nrdirhypers_x</th>\n      <th>nrhypos_x</th>\n      <th>nrpartrels_normalised_x</th>\n      <th>depthfromtopsynset_normalised_x</th>\n      <th>glosslength_normalised_x</th>\n      <th>minwordlength_x</th>\n      <th>nroflemmas_x</th>\n      <th>...</th>\n      <th>kbnc_1m_sum</th>\n      <th>childes_1m_rel_sum</th>\n      <th>childes_2_4m_rel_sum</th>\n      <th>childes_5_7m_rel_sum</th>\n      <th>bnc_1m_sum</th>\n      <th>bnc_5_7m_sum</th>\n      <th>bnc_2_4m_sum</th>\n      <th>bnc_100m_sum</th>\n      <th>cabnc_per_100k_2_4m</th>\n      <th>cabnc_per_100k_1m</th>\n    </tr>\n    <tr>\n      <th>norm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>adjustable_wrench</th>\n      <td>Synset('adjustable_wrench.n.01')</td>\n      <td>tool</td>\n      <td>-18.854402</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.563173</td>\n      <td>17</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>allen_wrench</th>\n      <td>Synset('allen_wrench.n.01')</td>\n      <td>tool</td>\n      <td>-18.389126</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.391092</td>\n      <td>12</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>alligator_wrench</th>\n      <td>Synset('alligator_wrench.n.01')</td>\n      <td>tool</td>\n      <td>-22.354690</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>1.517437</td>\n      <td>16</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>awl</th>\n      <td>Synset('awl.n.01')</td>\n      <td>tool</td>\n      <td>-14.809997</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15.7</td>\n      <td>0.911613</td>\n      <td>0.985552</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>39</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>backsaw</th>\n      <td>Synset('backsaw.n.01')</td>\n      <td>tool</td>\n      <td>-18.327476</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.114194</td>\n      <td>1.110701</td>\n      <td>7</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>ballet_skirt</th>\n      <td>Synset('ballet_skirt.n.01')</td>\n      <td>garm</td>\n      <td>-16.872435</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.947552</td>\n      <td>0.578283</td>\n      <td>4</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.754386e-07</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>33</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>mess_jacket</th>\n      <td>Synset('mess_jacket.n.01')</td>\n      <td>garm</td>\n      <td>-18.743772</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>1.652238</td>\n      <td>11</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>long_johns</th>\n      <td>Synset('long_johns.n.01')</td>\n      <td>garm</td>\n      <td>-16.882419</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.479149</td>\n      <td>10</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>undies</th>\n      <td>Synset('undies.n.01')</td>\n      <td>garm</td>\n      <td>-16.330160</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>0.280880</td>\n      <td>6</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>33</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>lingerie</th>\n      <td>Synset('lingerie.n.01')</td>\n      <td>garm</td>\n      <td>-15.203406</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.561761</td>\n      <td>8</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>67</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>839 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the pre-processed data all agreed\n",
    "data = pd.read_csv('./size_differential_features.csv', index_col=0)\n",
    "\n",
    "# generate the local dataframe for different domains\n",
    "local_fruit = data.loc[data['domain_x']=='fruit'].reset_index()\n",
    "local_tool = data.loc[data['domain_x']=='tool'].reset_index()\n",
    "local_music = data.loc[data['domain_x']=='music'].reset_index()\n",
    "local_furniture = data.loc[data['domain_x']=='furn'].reset_index()\n",
    "local_garments = data.loc[data['domain_x']=='garm'].reset_index()\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# define features and target\n",
    "features = ['ngrams_last_mean',\n",
    "            'nrdirhypers_x',\n",
    "            'nrhypos_x',\n",
    "            'nrpartrels_normalised_x',\n",
    "            'depthfromtopsynset_normalised_x',\n",
    "            'glosslength_normalised_x',\n",
    "            'minwordlength_x',\n",
    "            'nroflemmas_x',\n",
    "            'polyscore_max_x']\n",
    "target = ['vote_x'] # nb / b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# split training set and testing set using K-Flod\n",
    "def global_model_test(dataset, feature, sized_corpora, target):\n",
    "    K = 10\n",
    "    random_seed = 7 # R\n",
    "    data = dataset.reset_index()\n",
    "    feature_list = feature + [sized_corpora]\n",
    "    X = data[feature_list]\n",
    "    y = data[target]\n",
    "\n",
    "    K_Flod = StratifiedKFold(n_splits=K, shuffle=True, random_state=random_seed)\n",
    "    K_Flod.get_n_splits(X, y)\n",
    "    cohen_kappa = []\n",
    "    balanced_acc = []\n",
    "    for train_index, test_index in K_Flod.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # SMOTE algorithm\n",
    "        smote = SMOTE(random_state=random_seed, k_neighbors=2)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # define random forest model\n",
    "        rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "        # predict and make score\n",
    "        pipeline = make_pipeline(smote, rf)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "        cohen_kappa.append(kappa)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        balanced_acc.append(balanced_accuracy)\n",
    "\n",
    "    results = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results = pd.DataFrame(results).transpose()\n",
    "\n",
    "    results['cohen kappa / 10'] = np.mean(cohen_kappa)\n",
    "    results['balanced acc / 10'] = np.mean(balanced_acc)\n",
    "    results['global'] = 5\n",
    "\n",
    "    # importance of features\n",
    "    importance = rf.feature_importances_\n",
    "    importance = pd.DataFrame([features, importance]).transpose()\n",
    "    importance = importance.rename(columns={0:'feature', 1:'importance'}).sort_values('importance', ascending=False)\n",
    "\n",
    "    return results, importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KBNC: 1 million"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sized_corpora = 'kbnc_1m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.823529  0.823529  0.823529  17.000000          0.691517   \n nb             0.954545  0.954545  0.954545  66.000000          0.691517   \n accuracy       0.927711  0.927711  0.927711   0.927711          0.691517   \n macro avg      0.889037  0.889037  0.889037  83.000000          0.691517   \n weighted avg   0.927711  0.927711  0.927711  83.000000          0.691517   \n \n               balanced acc / 10  global  \n b                       0.85023       5  \n nb                      0.85023       5  \n accuracy                0.85023       5  \n macro avg               0.85023       5  \n weighted avg            0.85023       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.370331\n 5         glosslength_normalised_x   0.137375\n 0                 ngrams_last_mean   0.133441\n 6                  minwordlength_x   0.109875\n 3          nrpartrels_normalised_x   0.103399\n 2                        nrhypos_x   0.048189\n 9                              NaN   0.035055\n 8                  polyscore_max_x   0.033016\n 7                     nroflemmas_x   0.027104\n 1                    nrdirhypers_x   0.002215)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CABNC: 1 million, 2.4 million"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.736842  0.823529  0.777778  17.000000          0.685486   \n nb             0.953125  0.924242  0.938462  66.000000          0.685486   \n accuracy       0.903614  0.903614  0.903614   0.903614          0.685486   \n macro avg      0.844984  0.873886  0.858120  83.000000          0.685486   \n weighted avg   0.908826  0.903614  0.905550  83.000000          0.685486   \n \n               balanced acc / 10  global  \n b                      0.851834       5  \n nb                     0.851834       5  \n accuracy               0.851834       5  \n macro avg              0.851834       5  \n weighted avg           0.851834       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.373534\n 5         glosslength_normalised_x   0.138268\n 0                 ngrams_last_mean   0.133284\n 3          nrpartrels_normalised_x   0.106026\n 6                  minwordlength_x   0.105199\n 2                        nrhypos_x   0.045716\n 8                  polyscore_max_x   0.038181\n 9                              NaN    0.03012\n 7                     nroflemmas_x   0.027354\n 1                    nrdirhypers_x   0.002319)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'cabnc_per_100k_1m'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.789474  0.882353  0.833333  17.000000          0.699077   \n nb             0.968750  0.939394  0.953846  66.000000          0.699077   \n accuracy       0.927711  0.927711  0.927711   0.927711          0.699077   \n macro avg      0.879112  0.910873  0.893590  83.000000          0.699077   \n weighted avg   0.932031  0.927711  0.929163  83.000000          0.699077   \n \n               balanced acc / 10  global  \n b                      0.853742       5  \n nb                     0.853742       5  \n accuracy               0.853742       5  \n macro avg              0.853742       5  \n weighted avg           0.853742       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.370363\n 5         glosslength_normalised_x   0.149594\n 0                 ngrams_last_mean   0.130475\n 6                  minwordlength_x   0.106714\n 3          nrpartrels_normalised_x   0.101262\n 2                        nrhypos_x   0.041208\n 8                  polyscore_max_x   0.037968\n 9                              NaN   0.034192\n 7                     nroflemmas_x   0.025792\n 1                    nrdirhypers_x   0.002432)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'cabnc_per_100k_2_4m'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CHILDES: 5.7 million, 2.4 million, 1 million"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.842105  0.941176  0.888889  17.000000          0.685825   \n nb             0.984375  0.954545  0.969231  66.000000          0.685825   \n accuracy       0.951807  0.951807  0.951807   0.951807          0.685825   \n macro avg      0.913240  0.947861  0.929060  83.000000          0.685825   \n weighted avg   0.955235  0.951807  0.952775  83.000000          0.685825   \n \n               balanced acc / 10  global  \n b                      0.854018       5  \n nb                     0.854018       5  \n accuracy               0.854018       5  \n macro avg              0.854018       5  \n weighted avg           0.854018       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.363085\n 5         glosslength_normalised_x   0.133649\n 0                 ngrams_last_mean   0.123163\n 6                  minwordlength_x   0.106142\n 3          nrpartrels_normalised_x   0.082547\n 9                              NaN   0.082235\n 2                        nrhypos_x   0.042607\n 8                  polyscore_max_x   0.036329\n 7                     nroflemmas_x    0.02778\n 1                    nrdirhypers_x   0.002464)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'childes_1m_rel_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.842105  0.941176  0.888889  17.000000          0.683559   \n nb             0.984375  0.954545  0.969231  66.000000          0.683559   \n accuracy       0.951807  0.951807  0.951807   0.951807          0.683559   \n macro avg      0.913240  0.947861  0.929060  83.000000          0.683559   \n weighted avg   0.955235  0.951807  0.952775  83.000000          0.683559   \n \n               balanced acc / 10  global  \n b                      0.853283       5  \n nb                     0.853283       5  \n accuracy               0.853283       5  \n macro avg              0.853283       5  \n weighted avg           0.853283       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.367108\n 5         glosslength_normalised_x    0.13707\n 0                 ngrams_last_mean   0.128761\n 6                  minwordlength_x   0.108701\n 3          nrpartrels_normalised_x   0.082473\n 9                              NaN   0.063981\n 2                        nrhypos_x    0.04306\n 8                  polyscore_max_x   0.038121\n 7                     nroflemmas_x    0.02821\n 1                    nrdirhypers_x   0.002514)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'childes_2_4m_rel_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.833333  0.882353  0.857143  17.000000          0.660334   \n nb             0.969231  0.954545  0.961832  66.000000          0.660334   \n accuracy       0.939759  0.939759  0.939759   0.939759          0.660334   \n macro avg      0.901282  0.918449  0.909487  83.000000          0.660334   \n weighted avg   0.941396  0.939759  0.940390  83.000000          0.660334   \n \n               balanced acc / 10  global  \n b                      0.840341       5  \n nb                     0.840341       5  \n accuracy               0.840341       5  \n macro avg              0.840341       5  \n weighted avg           0.840341       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.364524\n 5         glosslength_normalised_x   0.136819\n 0                 ngrams_last_mean   0.131156\n 6                  minwordlength_x    0.11026\n 3          nrpartrels_normalised_x    0.08298\n 9                              NaN   0.064169\n 2                        nrhypos_x   0.042456\n 8                  polyscore_max_x   0.037328\n 7                     nroflemmas_x   0.027864\n 1                    nrdirhypers_x   0.002445)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'childes_5_7m_rel_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BNC: 100 million, 5.7 million, 2.4 million, 1 million"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.800000  0.941176  0.864865  17.000000          0.698233   \n nb             0.984127  0.939394  0.961240  66.000000          0.698233   \n accuracy       0.939759  0.939759  0.939759   0.939759          0.698233   \n macro avg      0.892063  0.940285  0.913053  83.000000          0.698233   \n weighted avg   0.946414  0.939759  0.941501  83.000000          0.698233   \n \n               balanced acc / 10  global  \n b                      0.853742       5  \n nb                     0.853742       5  \n accuracy               0.853742       5  \n macro avg              0.853742       5  \n weighted avg           0.853742       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.368128\n 5         glosslength_normalised_x   0.138929\n 0                 ngrams_last_mean   0.129226\n 3          nrpartrels_normalised_x   0.109587\n 6                  minwordlength_x    0.10661\n 2                        nrhypos_x   0.043291\n 9                              NaN   0.039832\n 8                  polyscore_max_x   0.033136\n 7                     nroflemmas_x   0.029014\n 1                    nrdirhypers_x   0.002247)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'bnc_1m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.789474  0.882353  0.833333  17.000000          0.709009   \n nb             0.968750  0.939394  0.953846  66.000000          0.709009   \n accuracy       0.927711  0.927711  0.927711   0.927711          0.709009   \n macro avg      0.879112  0.910873  0.893590  83.000000          0.709009   \n weighted avg   0.932031  0.927711  0.929163  83.000000          0.709009   \n \n               balanced acc / 10  global  \n b                      0.860044       5  \n nb                     0.860044       5  \n accuracy               0.860044       5  \n macro avg              0.860044       5  \n weighted avg           0.860044       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.359973\n 5         glosslength_normalised_x   0.141079\n 0                 ngrams_last_mean   0.126889\n 3          nrpartrels_normalised_x    0.11451\n 6                  minwordlength_x   0.102736\n 9                              NaN   0.046835\n 2                        nrhypos_x   0.044841\n 8                  polyscore_max_x   0.032984\n 7                     nroflemmas_x   0.028021\n 1                    nrdirhypers_x   0.002132)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'bnc_2_4m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.888889  0.941176  0.914286  17.000000          0.712823   \n nb             0.984615  0.969697  0.977099  66.000000          0.712823   \n accuracy       0.963855  0.963855  0.963855   0.963855          0.712823   \n macro avg      0.936752  0.955437  0.945692  83.000000          0.712823   \n weighted avg   0.965009  0.963855  0.964234  83.000000          0.712823   \n \n               balanced acc / 10  global  \n b                      0.860965       5  \n nb                     0.860965       5  \n accuracy               0.860965       5  \n macro avg              0.860965       5  \n weighted avg           0.860965       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.356451\n 5         glosslength_normalised_x   0.132684\n 0                 ngrams_last_mean   0.128223\n 3          nrpartrels_normalised_x   0.117791\n 6                  minwordlength_x   0.102111\n 9                              NaN   0.056655\n 2                        nrhypos_x   0.044823\n 8                  polyscore_max_x   0.032861\n 7                     nroflemmas_x   0.026702\n 1                    nrdirhypers_x   0.001698)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'bnc_5_7m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.842105  0.941176  0.888889  17.000000          0.714009   \n nb             0.984375  0.954545  0.969231  66.000000          0.714009   \n accuracy       0.951807  0.951807  0.951807   0.951807          0.714009   \n macro avg      0.913240  0.947861  0.929060  83.000000          0.714009   \n weighted avg   0.955235  0.951807  0.952775  83.000000          0.714009   \n \n               balanced acc / 10  global  \n b                      0.859528       5  \n nb                     0.859528       5  \n accuracy               0.859528       5  \n macro avg              0.859528       5  \n weighted avg           0.859528       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.340294\n 3          nrpartrels_normalised_x   0.141376\n 5         glosslength_normalised_x   0.125519\n 0                 ngrams_last_mean   0.117697\n 6                  minwordlength_x   0.094382\n 9                              NaN   0.081304\n 2                        nrhypos_x   0.045248\n 8                  polyscore_max_x   0.027948\n 7                     nroflemmas_x   0.024461\n 1                    nrdirhypers_x   0.001771)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'bnc_100m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tset: next stage feature engineering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            Synsets domain_x  \\\nnorm                                                           \nadjustable_wrench  Synset('adjustable_wrench.n.01')     tool   \nallen_wrench            Synset('allen_wrench.n.01')     tool   \nalligator_wrench    Synset('alligator_wrench.n.01')     tool   \nawl                              Synset('awl.n.01')     tool   \nbacksaw                      Synset('backsaw.n.01')     tool   \n...                                             ...      ...   \nballet_skirt            Synset('ballet_skirt.n.01')     garm   \nmess_jacket              Synset('mess_jacket.n.01')     garm   \nlong_johns                Synset('long_johns.n.01')     garm   \nundies                        Synset('undies.n.01')     garm   \nlingerie                    Synset('lingerie.n.01')     garm   \n\n                   ngrams_last_mean  nrdirhypers_x  nrhypos_x  \\\nnorm                                                            \nadjustable_wrench        -18.854402              1          7   \nallen_wrench             -18.389126              1          0   \nalligator_wrench         -22.354690              1          0   \nawl                      -14.809997              1          2   \nbacksaw                  -18.327476              1          0   \n...                             ...            ...        ...   \nballet_skirt             -16.872435              1          0   \nmess_jacket              -18.743772              1          0   \nlong_johns               -16.882419              1          0   \nundies                   -16.330160              1          0   \nlingerie                 -15.203406              1          2   \n\n                   nrpartrels_normalised_x  depthfromtopsynset_normalised_x  \\\nnorm                                                                          \nadjustable_wrench                      0.0                         1.012903   \nallen_wrench                           0.0                         1.012903   \nalligator_wrench                       0.0                         1.012903   \nawl                                   15.7                         0.911613   \nbacksaw                                0.0                         1.114194   \n...                                    ...                              ...   \nballet_skirt                           0.0                         0.947552   \nmess_jacket                            0.0                         1.158120   \nlong_johns                             0.0                         1.052836   \nundies                                 0.0                         1.158120   \nlingerie                               0.0                         1.052836   \n\n                   glosslength_normalised_x  minwordlength_x  nroflemmas_x  \\\nnorm                                                                         \nadjustable_wrench                  0.563173               17             2   \nallen_wrench                       0.391092               12             1   \nalligator_wrench                   1.517437               16             1   \nawl                                0.985552                3             1   \nbacksaw                            1.110701                7             2   \n...                                     ...              ...           ...   \nballet_skirt                       0.578283                4             2   \nmess_jacket                        1.652238               11             3   \nlong_johns                         0.479149               10             1   \nundies                             0.280880                6             1   \nlingerie                           0.561761                8             2   \n\n                   ...  min_5_7m min_100m  sum_1m  sum_2_4m  sum_5_7m  \\\nnorm               ...                                                  \nadjustable_wrench  ...         0        0       0         0         0   \nallen_wrench       ...         0        0       0         0         0   \nalligator_wrench   ...         0        0       0         0         0   \nawl                ...         0       39       1         1         3   \nbacksaw            ...         0        0       0         0         0   \n...                ...       ...      ...     ...       ...       ...   \nballet_skirt       ...         0       33       0         0         1   \nmess_jacket        ...         0        0       0         0         0   \nlong_johns         ...         0        0       0         0         0   \nundies             ...         0       33       1         1         1   \nlingerie           ...         0       67       1         1         1   \n\n                   sum_100m  avg_bnc  avg_childes  avg_cabnc  avg_kbnc  \nnorm                                                                    \nadjustable_wrench         0     0.00     0.000000        0.0       0.0  \nallen_wrench              0     0.00     0.000000        0.0       0.0  \nalligator_wrench          0     0.00     0.000000        0.0       0.0  \nawl                      39    11.00     0.000000        0.0       0.0  \nbacksaw                   0     0.00     0.000000        0.0       0.0  \n...                     ...      ...          ...        ...       ...  \nballet_skirt             33     8.25     0.333333        0.0       0.0  \nmess_jacket               0     0.00     0.000000        0.0       0.0  \nlong_johns                0     0.00     0.000000        0.0       0.0  \nundies                   33     9.00     0.000000        0.0       0.0  \nlingerie                 67    17.50     0.000000        0.0       0.0  \n\n[839 rows x 43 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Synsets</th>\n      <th>domain_x</th>\n      <th>ngrams_last_mean</th>\n      <th>nrdirhypers_x</th>\n      <th>nrhypos_x</th>\n      <th>nrpartrels_normalised_x</th>\n      <th>depthfromtopsynset_normalised_x</th>\n      <th>glosslength_normalised_x</th>\n      <th>minwordlength_x</th>\n      <th>nroflemmas_x</th>\n      <th>...</th>\n      <th>min_5_7m</th>\n      <th>min_100m</th>\n      <th>sum_1m</th>\n      <th>sum_2_4m</th>\n      <th>sum_5_7m</th>\n      <th>sum_100m</th>\n      <th>avg_bnc</th>\n      <th>avg_childes</th>\n      <th>avg_cabnc</th>\n      <th>avg_kbnc</th>\n    </tr>\n    <tr>\n      <th>norm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>adjustable_wrench</th>\n      <td>Synset('adjustable_wrench.n.01')</td>\n      <td>tool</td>\n      <td>-18.854402</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.563173</td>\n      <td>17</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>allen_wrench</th>\n      <td>Synset('allen_wrench.n.01')</td>\n      <td>tool</td>\n      <td>-18.389126</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.391092</td>\n      <td>12</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>alligator_wrench</th>\n      <td>Synset('alligator_wrench.n.01')</td>\n      <td>tool</td>\n      <td>-22.354690</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>1.517437</td>\n      <td>16</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>awl</th>\n      <td>Synset('awl.n.01')</td>\n      <td>tool</td>\n      <td>-14.809997</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15.7</td>\n      <td>0.911613</td>\n      <td>0.985552</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>39</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>39</td>\n      <td>11.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>backsaw</th>\n      <td>Synset('backsaw.n.01')</td>\n      <td>tool</td>\n      <td>-18.327476</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.114194</td>\n      <td>1.110701</td>\n      <td>7</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>ballet_skirt</th>\n      <td>Synset('ballet_skirt.n.01')</td>\n      <td>garm</td>\n      <td>-16.872435</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.947552</td>\n      <td>0.578283</td>\n      <td>4</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>33</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>33</td>\n      <td>8.25</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>mess_jacket</th>\n      <td>Synset('mess_jacket.n.01')</td>\n      <td>garm</td>\n      <td>-18.743772</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>1.652238</td>\n      <td>11</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>long_johns</th>\n      <td>Synset('long_johns.n.01')</td>\n      <td>garm</td>\n      <td>-16.882419</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.479149</td>\n      <td>10</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>undies</th>\n      <td>Synset('undies.n.01')</td>\n      <td>garm</td>\n      <td>-16.330160</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>0.280880</td>\n      <td>6</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>33</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>33</td>\n      <td>9.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>lingerie</th>\n      <td>Synset('lingerie.n.01')</td>\n      <td>garm</td>\n      <td>-15.203406</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.561761</td>\n      <td>8</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>67</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>67</td>\n      <td>17.50</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>839 rows × 43 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the pre-processed data all agreed\n",
    "data = pd.read_csv('./next_stage_size_differential_features.csv', index_col=0)\n",
    "\n",
    "# generate the local dataframe for different domains\n",
    "local_fruit = data.loc[data['domain_x']=='fruit'].reset_index()\n",
    "local_tool = data.loc[data['domain_x']=='tool'].reset_index()\n",
    "local_music = data.loc[data['domain_x']=='music'].reset_index()\n",
    "local_furniture = data.loc[data['domain_x']=='furn'].reset_index()\n",
    "local_garments = data.loc[data['domain_x']=='garm'].reset_index()\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# split training set and testing set using K-Flod\n",
    "def new_features_global_model_test(dataset, feature, new_features, target):\n",
    "    K = 10\n",
    "    random_seed = 7 # R\n",
    "    data = dataset.reset_index()\n",
    "    feature_list = feature + new_features\n",
    "    X = data[feature_list]\n",
    "    y = data[target]\n",
    "\n",
    "    K_Flod = StratifiedKFold(n_splits=K, shuffle=True, random_state=random_seed)\n",
    "    K_Flod.get_n_splits(X, y)\n",
    "    cohen_kappa = []\n",
    "    balanced_acc = []\n",
    "    for train_index, test_index in K_Flod.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # SMOTE algorithm\n",
    "        smote = SMOTE(random_state=random_seed, k_neighbors=2)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # define random forest model\n",
    "        rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "        # predict and make score\n",
    "        pipeline = make_pipeline(smote, rf)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "        cohen_kappa.append(kappa)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        balanced_acc.append(balanced_accuracy)\n",
    "\n",
    "    results = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results = pd.DataFrame(results).transpose()\n",
    "\n",
    "    results['cohen kappa / 10'] = np.mean(cohen_kappa)\n",
    "    results['balanced acc / 10'] = np.mean(balanced_acc)\n",
    "    results['global'] = 5\n",
    "\n",
    "    # importance of features\n",
    "    importance = rf.feature_importances_\n",
    "    importance = pd.DataFrame([feature_list, importance]).transpose()\n",
    "    importance = importance.rename(columns={0:'feature', 1:'importance'}).sort_values('importance', ascending=False)\n",
    "\n",
    "    return results, importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.882353  0.882353  0.882353  17.000000          0.655853   \n nb             0.969697  0.969697  0.969697  66.000000          0.655853   \n accuracy       0.951807  0.951807  0.951807   0.951807          0.655853   \n macro avg      0.926025  0.926025  0.926025  83.000000          0.655853   \n weighted avg   0.951807  0.951807  0.951807  83.000000          0.655853   \n \n               balanced acc / 10  global  \n b                       0.84081       5  \n nb                      0.84081       5  \n accuracy                0.84081       5  \n macro avg               0.84081       5  \n weighted avg            0.84081       5  ,\n                             feature importance\n 4   depthfromtopsynset_normalised_x    0.28202\n 5          glosslength_normalised_x   0.111131\n 3           nrpartrels_normalised_x   0.104112\n 0                  ngrams_last_mean   0.083509\n 6                   minwordlength_x   0.068086\n 20                         sum_100m   0.030549\n 12                         max_100m   0.030286\n 16                         min_100m   0.029838\n 21                          avg_bnc   0.029823\n 2                         nrhypos_x   0.029271\n 24                         avg_kbnc   0.027076\n 22                      avg_childes   0.026998\n 7                      nroflemmas_x   0.017852\n 17                           sum_1m   0.016177\n 8                   polyscore_max_x   0.016091\n 19                         sum_5_7m    0.01555\n 11                         max_5_7m   0.015285\n 9                            max_1m   0.014934\n 10                         max_2_4m    0.01125\n 18                         sum_2_4m    0.01065\n 23                        avg_cabnc   0.009503\n 15                         min_5_7m   0.008215\n 14                         min_2_4m   0.006059\n 13                           min_1m   0.004318\n 1                     nrdirhypers_x   0.001418)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top-down method\n",
    "new_feature = ['max_1m','max_2_4m','max_5_7m','max_100m','min_1m','min_2_4m','min_5_7m','min_100m','sum_1m','sum_2_4m','sum_5_7m','sum_100m','avg_bnc','avg_childes','avg_cabnc','avg_kbnc']\n",
    "new_features_global_model_test(data, features, new_feature, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.882353  0.882353  0.882353  17.000000          0.661393   \n nb             0.969697  0.969697  0.969697  66.000000          0.661393   \n accuracy       0.951807  0.951807  0.951807   0.951807          0.661393   \n macro avg      0.926025  0.926025  0.926025  83.000000          0.661393   \n weighted avg   0.951807  0.951807  0.951807  83.000000          0.661393   \n \n               balanced acc / 10  global  \n b                      0.842291       5  \n nb                     0.842291       5  \n accuracy               0.842291       5  \n macro avg              0.842291       5  \n weighted avg           0.842291       5  ,\n                             feature importance\n 4   depthfromtopsynset_normalised_x    0.26325\n 5          glosslength_normalised_x   0.110669\n 3           nrpartrels_normalised_x   0.101248\n 0                  ngrams_last_mean   0.083231\n 6                   minwordlength_x     0.0666\n 19                         sum_100m   0.032944\n 20                          avg_bnc   0.032891\n 12                         max_100m    0.03153\n 15                         min_100m   0.031167\n 2                         nrhypos_x   0.029486\n 23                         avg_kbnc   0.029468\n 21                      avg_childes    0.02744\n 7                      nroflemmas_x   0.018955\n 16                           sum_1m   0.018179\n 18                         sum_5_7m   0.018068\n 8                   polyscore_max_x   0.017671\n 9                            max_1m   0.016368\n 11                         max_5_7m     0.0163\n 17                         sum_2_4m    0.01341\n 10                         max_2_4m   0.012747\n 22                        avg_cabnc   0.010318\n 14                         min_5_7m   0.009988\n 13                         min_2_4m   0.006622\n 1                     nrdirhypers_x    0.00145)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove min_1m\n",
    "new_feature = ['max_1m','max_2_4m','max_5_7m','max_100m','min_2_4m','min_5_7m','min_100m','sum_1m','sum_2_4m','sum_5_7m','sum_100m','avg_bnc','avg_childes','avg_cabnc','avg_kbnc']\n",
    "new_features_global_model_test(data, features, new_feature, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.842105  0.941176  0.888889  17.000000          0.714009   \n nb             0.984375  0.954545  0.969231  66.000000          0.714009   \n accuracy       0.951807  0.951807  0.951807   0.951807          0.714009   \n macro avg      0.913240  0.947861  0.929060  83.000000          0.714009   \n weighted avg   0.955235  0.951807  0.952775  83.000000          0.714009   \n \n               balanced acc / 10  global  \n b                      0.859528       5  \n nb                     0.859528       5  \n accuracy               0.859528       5  \n macro avg              0.859528       5  \n weighted avg           0.859528       5  ,\n                            feature importance\n 4  depthfromtopsynset_normalised_x   0.340294\n 3          nrpartrels_normalised_x   0.141376\n 5         glosslength_normalised_x   0.125519\n 0                 ngrams_last_mean   0.117697\n 6                  minwordlength_x   0.094382\n 9                     bnc_100m_sum   0.081304\n 2                        nrhypos_x   0.045248\n 8                  polyscore_max_x   0.027948\n 7                     nroflemmas_x   0.024461\n 1                    nrdirhypers_x   0.001771)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add bnc_100m_sum\n",
    "new_feature = ['bnc_100m_sum']\n",
    "new_features_global_model_test(data, features, new_feature, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: max_1m\n",
      "0.7092324905618889\n",
      "max_1m\n",
      "              precision    recall  f1-score    support  cohen kappa / 10  \\\n",
      "b              0.842105  0.941176  0.888889  17.000000          0.709232   \n",
      "nb             0.984375  0.954545  0.969231  66.000000          0.709232   \n",
      "accuracy       0.951807  0.951807  0.951807   0.951807          0.709232   \n",
      "macro avg      0.913240  0.947861  0.929060  83.000000          0.709232   \n",
      "weighted avg   0.955235  0.951807  0.952775  83.000000          0.709232   \n",
      "\n",
      "              balanced acc / 10  global  \n",
      "b                      0.863851       5  \n",
      "nb                     0.863851       5  \n",
      "accuracy               0.863851       5  \n",
      "macro avg              0.863851       5  \n",
      "weighted avg           0.863851       5  \n",
      "                            feature importance\n",
      "4   depthfromtopsynset_normalised_x   0.332077\n",
      "5          glosslength_normalised_x   0.126464\n",
      "3           nrpartrels_normalised_x   0.124124\n",
      "0                  ngrams_last_mean   0.111875\n",
      "6                   minwordlength_x   0.092228\n",
      "9                      bnc_100m_sum   0.072634\n",
      "10                           max_1m   0.045508\n",
      "2                         nrhypos_x   0.044064\n",
      "8                   polyscore_max_x   0.025926\n",
      "7                      nroflemmas_x   0.023572\n",
      "1                     nrdirhypers_x   0.001528\n",
      "feature: max_2_4m\n",
      "feature: max_5_7m\n",
      "feature: max_100m\n",
      "feature: min_1m\n",
      "0.7151446812085501\n",
      "min_1m\n",
      "              precision    recall  f1-score    support  cohen kappa / 10  \\\n",
      "b              0.842105  0.941176  0.888889  17.000000          0.715145   \n",
      "nb             0.984375  0.954545  0.969231  66.000000          0.715145   \n",
      "accuracy       0.951807  0.951807  0.951807   0.951807          0.715145   \n",
      "macro avg      0.913240  0.947861  0.929060  83.000000          0.715145   \n",
      "weighted avg   0.955235  0.951807  0.952775  83.000000          0.715145   \n",
      "\n",
      "              balanced acc / 10  global  \n",
      "b                       0.85968       5  \n",
      "nb                      0.85968       5  \n",
      "accuracy                0.85968       5  \n",
      "macro avg               0.85968       5  \n",
      "weighted avg            0.85968       5  \n",
      "                            feature importance\n",
      "4   depthfromtopsynset_normalised_x   0.334585\n",
      "3           nrpartrels_normalised_x   0.131987\n",
      "5          glosslength_normalised_x   0.127887\n",
      "0                  ngrams_last_mean   0.113404\n",
      "6                   minwordlength_x   0.095902\n",
      "9                      bnc_100m_sum   0.080378\n",
      "2                         nrhypos_x   0.044932\n",
      "8                   polyscore_max_x   0.027453\n",
      "7                      nroflemmas_x   0.023846\n",
      "10                           min_1m   0.017896\n",
      "1                     nrdirhypers_x   0.001728\n",
      "feature: min_2_4m\n",
      "feature: min_5_7m\n",
      "feature: min_100m\n",
      "feature: sum_1m\n",
      "feature: sum_2_4m\n",
      "feature: sum_5_7m\n",
      "feature: sum_100m\n",
      "feature: avg_bnc\n",
      "feature: avg_childes\n",
      "feature: avg_cabnc\n",
      "feature: avg_kbnc\n"
     ]
    }
   ],
   "source": [
    "# bottom-up method +1\n",
    "new_feature = ['max_1m','max_2_4m','max_5_7m','max_100m','min_1m','min_2_4m','min_5_7m','min_100m','sum_1m','sum_2_4m','sum_5_7m','sum_100m','avg_bnc','avg_childes','avg_cabnc','avg_kbnc']\n",
    "max_kappa = 0.714009\n",
    "for i in new_feature:\n",
    "    print(\"feature: \" + i)\n",
    "    new = ['bnc_100m_sum'] + [i]\n",
    "    res, f_importance = new_features_global_model_test(data, features, new, target)\n",
    "    if res['cohen kappa / 10'][0] > max_kappa:\n",
    "        max_kappa = res['cohen kappa / 10'][0]\n",
    "        print(max_kappa)\n",
    "        print(i)\n",
    "        print(res)\n",
    "        print(f_importance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: max_1m\n",
      "feature: max_2_4m\n",
      "feature: max_5_7m\n",
      "feature: max_100m\n",
      "feature: min_2_4m\n",
      "feature: min_5_7m\n",
      "feature: min_100m\n",
      "feature: sum_1m\n",
      "feature: sum_2_4m\n",
      "feature: sum_5_7m\n",
      "feature: sum_100m\n",
      "feature: avg_bnc\n",
      "feature: avg_childes\n",
      "feature: avg_cabnc\n"
     ]
    }
   ],
   "source": [
    "# bottom-up method +2 (base: min_1m)\n",
    "new_feature = ['max_1m', 'max_2_4m','max_5_7m','max_100m','min_2_4m','min_5_7m','min_100m','sum_1m','sum_2_4m','sum_5_7m','sum_100m','avg_bnc','avg_childes','avg_cabnc','avg_kbnc']\n",
    "max_kappa = 0.715145\n",
    "for i in new_feature:\n",
    "    print(\"feature: \" + i)\n",
    "    new = ['bnc_100m_sum', 'min_1m'] + [i]\n",
    "    res, f_importance = new_features_global_model_test(data, features, new, target)\n",
    "    if res['cohen kappa / 10'][0] > max_kappa:\n",
    "        max_kappa = res['cohen kappa / 10'][0]\n",
    "        print(max_kappa)\n",
    "        print(i)\n",
    "        print(res)\n",
    "        print(f_importance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}