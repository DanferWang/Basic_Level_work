{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score, balanced_accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                 domain_x  nrdirhypers_x  nrhypos_x  \\\nSynsets                                                               \nSynset('adjustable_wrench.n.01')     tool              1          7   \nSynset('allen_wrench.n.01')          tool              1          0   \nSynset('alligator_wrench.n.01')      tool              1          0   \nSynset('awl.n.01')                   tool              1          2   \nSynset('backsaw.n.01')               tool              1          0   \n...                                   ...            ...        ...   \nSynset('ballet_skirt.n.01')          garm              1          0   \nSynset('mess_jacket.n.01')           garm              1          0   \nSynset('long_johns.n.01')            garm              1          0   \nSynset('undies.n.01')                garm              1          0   \nSynset('lingerie.n.01')              garm              1          2   \n\n                                  nrpartrels_normalised_x  \\\nSynsets                                                     \nSynset('adjustable_wrench.n.01')                      0.0   \nSynset('allen_wrench.n.01')                           0.0   \nSynset('alligator_wrench.n.01')                       0.0   \nSynset('awl.n.01')                                   15.7   \nSynset('backsaw.n.01')                                0.0   \n...                                                   ...   \nSynset('ballet_skirt.n.01')                           0.0   \nSynset('mess_jacket.n.01')                            0.0   \nSynset('long_johns.n.01')                             0.0   \nSynset('undies.n.01')                                 0.0   \nSynset('lingerie.n.01')                               0.0   \n\n                                  depthfromtopsynset_normalised_x  \\\nSynsets                                                             \nSynset('adjustable_wrench.n.01')                         1.012903   \nSynset('allen_wrench.n.01')                              1.012903   \nSynset('alligator_wrench.n.01')                          1.012903   \nSynset('awl.n.01')                                       0.911613   \nSynset('backsaw.n.01')                                   1.114194   \n...                                                           ...   \nSynset('ballet_skirt.n.01')                              0.947552   \nSynset('mess_jacket.n.01')                               1.158120   \nSynset('long_johns.n.01')                                1.052836   \nSynset('undies.n.01')                                    1.158120   \nSynset('lingerie.n.01')                                  1.052836   \n\n                                  glosslength_normalised_x  minwordlength_x  \\\nSynsets                                                                       \nSynset('adjustable_wrench.n.01')                  0.563173               17   \nSynset('allen_wrench.n.01')                       0.391092               12   \nSynset('alligator_wrench.n.01')                   1.517437               16   \nSynset('awl.n.01')                                0.985552                3   \nSynset('backsaw.n.01')                            1.110701                7   \n...                                                    ...              ...   \nSynset('ballet_skirt.n.01')                       0.578283                4   \nSynset('mess_jacket.n.01')                        1.652238               11   \nSynset('long_johns.n.01')                         0.479149               10   \nSynset('undies.n.01')                             0.280880                6   \nSynset('lingerie.n.01')                           0.561761                8   \n\n                                  nroflemmas_x  polyscore_max_x vote_x  \\\nSynsets                                                                  \nSynset('adjustable_wrench.n.01')             2                1     nb   \nSynset('allen_wrench.n.01')                  1                1     nb   \nSynset('alligator_wrench.n.01')              1                1     nb   \nSynset('awl.n.01')                           1                1      b   \nSynset('backsaw.n.01')                       2                1     nb   \n...                                        ...              ...    ...   \nSynset('ballet_skirt.n.01')                  2                2     nb   \nSynset('mess_jacket.n.01')                   3                1     nb   \nSynset('long_johns.n.01')                    1                1     nb   \nSynset('undies.n.01')                        1                1     nb   \nSynset('lingerie.n.01')                      2                1     nb   \n\n                                  ngram_2009_2019_original_sleep  \\\nSynsets                                                            \nSynset('adjustable_wrench.n.01')                    2.460615e-08   \nSynset('allen_wrench.n.01')                         1.601034e-08   \nSynset('alligator_wrench.n.01')                     1.236022e-10   \nSynset('awl.n.01')                                  2.805608e-07   \nSynset('backsaw.n.01')                              1.135172e-08   \n...                                                          ...   \nSynset('ballet_skirt.n.01')                         5.498723e-07   \nSynset('mess_jacket.n.01')                          1.454007e-08   \nSynset('long_johns.n.01')                           8.935307e-08   \nSynset('undies.n.01')                               2.118603e-07   \nSynset('lingerie.n.01')                             9.058988e-07   \n\n                                  ngram_2009_2019_updata_sleep  \nSynsets                                                         \nSynset('adjustable_wrench.n.01')                  2.460615e-08  \nSynset('allen_wrench.n.01')                       1.601034e-08  \nSynset('alligator_wrench.n.01')                   1.236022e-10  \nSynset('awl.n.01')                                2.805608e-07  \nSynset('backsaw.n.01')                            1.135172e-08  \n...                                                        ...  \nSynset('ballet_skirt.n.01')                       5.498723e-07  \nSynset('mess_jacket.n.01')                        1.454007e-08  \nSynset('long_johns.n.01')                         8.935307e-08  \nSynset('undies.n.01')                             2.118603e-07  \nSynset('lingerie.n.01')                           9.058988e-07  \n\n[839 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>domain_x</th>\n      <th>nrdirhypers_x</th>\n      <th>nrhypos_x</th>\n      <th>nrpartrels_normalised_x</th>\n      <th>depthfromtopsynset_normalised_x</th>\n      <th>glosslength_normalised_x</th>\n      <th>minwordlength_x</th>\n      <th>nroflemmas_x</th>\n      <th>polyscore_max_x</th>\n      <th>vote_x</th>\n      <th>ngram_2009_2019_original_sleep</th>\n      <th>ngram_2009_2019_updata_sleep</th>\n    </tr>\n    <tr>\n      <th>Synsets</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Synset('adjustable_wrench.n.01')</th>\n      <td>tool</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.563173</td>\n      <td>17</td>\n      <td>2</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>2.460615e-08</td>\n      <td>2.460615e-08</td>\n    </tr>\n    <tr>\n      <th>Synset('allen_wrench.n.01')</th>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.391092</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>1.601034e-08</td>\n      <td>1.601034e-08</td>\n    </tr>\n    <tr>\n      <th>Synset('alligator_wrench.n.01')</th>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>1.517437</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>1.236022e-10</td>\n      <td>1.236022e-10</td>\n    </tr>\n    <tr>\n      <th>Synset('awl.n.01')</th>\n      <td>tool</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15.7</td>\n      <td>0.911613</td>\n      <td>0.985552</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>b</td>\n      <td>2.805608e-07</td>\n      <td>2.805608e-07</td>\n    </tr>\n    <tr>\n      <th>Synset('backsaw.n.01')</th>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.114194</td>\n      <td>1.110701</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>1.135172e-08</td>\n      <td>1.135172e-08</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Synset('ballet_skirt.n.01')</th>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.947552</td>\n      <td>0.578283</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>nb</td>\n      <td>5.498723e-07</td>\n      <td>5.498723e-07</td>\n    </tr>\n    <tr>\n      <th>Synset('mess_jacket.n.01')</th>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>1.652238</td>\n      <td>11</td>\n      <td>3</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>1.454007e-08</td>\n      <td>1.454007e-08</td>\n    </tr>\n    <tr>\n      <th>Synset('long_johns.n.01')</th>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.479149</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>8.935307e-08</td>\n      <td>8.935307e-08</td>\n    </tr>\n    <tr>\n      <th>Synset('undies.n.01')</th>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>0.280880</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>2.118603e-07</td>\n      <td>2.118603e-07</td>\n    </tr>\n    <tr>\n      <th>Synset('lingerie.n.01')</th>\n      <td>garm</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.561761</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>9.058988e-07</td>\n      <td>9.058988e-07</td>\n    </tr>\n  </tbody>\n</table>\n<p>839 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the pre-processed data all agreed\n",
    "data = pd.read_csv('./Google_Ngrams/features_google_ngram.csv', index_col=0)\n",
    "\n",
    "# generate the local dataframe for different domains\n",
    "local_fruit = data.loc[data['domain_x']=='fruit'].reset_index()\n",
    "local_tool = data.loc[data['domain_x']=='tool'].reset_index()\n",
    "local_music = data.loc[data['domain_x']=='music'].reset_index()\n",
    "local_furniture = data.loc[data['domain_x']=='furn'].reset_index()\n",
    "local_garments = data.loc[data['domain_x']=='garm'].reset_index()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# define features and target\n",
    "features = ['nrdirhypers_x',\n",
    "            'nrhypos_x',\n",
    "            'nrpartrels_normalised_x',\n",
    "            'depthfromtopsynset_normalised_x',\n",
    "            'glosslength_normalised_x',\n",
    "            'minwordlength_x',\n",
    "            'nroflemmas_x',\n",
    "            'polyscore_max_x']\n",
    "target = ['vote_x'] # nb / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# split training set and testing set using K-Flod\n",
    "def global_model_test(dataset, feature, sized_corpora, target):\n",
    "    K = 10\n",
    "    random_seed = 7 # R\n",
    "    data = dataset.reset_index()\n",
    "    feature_list = feature + [sized_corpora]\n",
    "    X = data[feature_list]\n",
    "    y = data[target]\n",
    "\n",
    "    K_Flod = StratifiedKFold(n_splits=K, shuffle=True, random_state=random_seed)\n",
    "    K_Flod.get_n_splits(X, y)\n",
    "    cohen_kappa = []\n",
    "    balanced_acc = []\n",
    "    for train_index, test_index in K_Flod.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # SMOTE algorithm\n",
    "        smote = SMOTE(random_state=random_seed, k_neighbors=2)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # define random forest model\n",
    "        rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "        # predict and make score\n",
    "        pipeline = make_pipeline(smote, rf)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "        cohen_kappa.append(kappa)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        balanced_acc.append(balanced_accuracy)\n",
    "\n",
    "    results = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results = pd.DataFrame(results).transpose()\n",
    "\n",
    "    results['cohen kappa / 10'] = np.mean(cohen_kappa)\n",
    "    results['balanced acc / 10'] = np.mean(balanced_acc)\n",
    "    results['global'] = 5\n",
    "\n",
    "    # importance of features\n",
    "    importance = rf.feature_importances_\n",
    "    importance = pd.DataFrame([feature_list, importance]).transpose()\n",
    "    importance = importance.rename(columns={0:'feature', 1:'importance'}).sort_values('importance', ascending=False)\n",
    "\n",
    "    return results, importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## KBNC: 1 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.866667  0.764706  0.812500  17.000000          0.687594   \n nb             0.941176  0.969697  0.955224  66.000000          0.687594   \n accuracy       0.927711  0.927711  0.927711   0.927711          0.687594   \n macro avg      0.903922  0.867201  0.883862  83.000000          0.687594   \n weighted avg   0.925915  0.927711  0.925991  83.000000          0.687594   \n \n               balanced acc / 10  global  \n b                      0.850898       5  \n nb                     0.850898       5  \n accuracy               0.850898       5  \n macro avg              0.850898       5  \n weighted avg           0.850898       5  ,\n                            feature importance\n 3  depthfromtopsynset_normalised_x   0.432792\n 4         glosslength_normalised_x   0.154475\n 5                  minwordlength_x   0.122853\n 2          nrpartrels_normalised_x   0.098376\n 1                        nrhypos_x   0.062018\n 8                      kbnc_1m_sum   0.051115\n 7                  polyscore_max_x   0.043319\n 6                     nroflemmas_x   0.031687\n 0                    nrdirhypers_x   0.003364)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'kbnc_1m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CABNC: 1 million, 2.4 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.764706  0.764706  0.764706  17.000000          0.674959   \n nb             0.939394  0.939394  0.939394  66.000000          0.674959   \n accuracy       0.903614  0.903614  0.903614   0.903614          0.674959   \n macro avg      0.852050  0.852050  0.852050  83.000000          0.674959   \n weighted avg   0.903614  0.903614  0.903614  83.000000          0.674959   \n \n               balanced acc / 10  global  \n b                      0.838758       5  \n nb                     0.838758       5  \n accuracy               0.838758       5  \n macro avg              0.838758       5  \n weighted avg           0.838758       5  ,\n                            feature importance\n 3  depthfromtopsynset_normalised_x   0.414127\n 4         glosslength_normalised_x   0.163589\n 5                  minwordlength_x   0.120528\n 2          nrpartrels_normalised_x   0.103535\n 1                        nrhypos_x   0.058441\n 7                  polyscore_max_x   0.052864\n 8                cabnc_per_100k_1m   0.052773\n 6                     nroflemmas_x   0.030924\n 0                    nrdirhypers_x   0.003219)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'cabnc_per_100k_1m'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.777778  0.823529  0.800000  17.000000          0.687207   \n nb             0.953846  0.939394  0.946565  66.000000          0.687207   \n accuracy       0.915663  0.915663  0.915663   0.915663          0.687207   \n macro avg      0.865812  0.881462  0.873282  83.000000          0.687207   \n weighted avg   0.917784  0.915663  0.916546  83.000000          0.687207   \n \n               balanced acc / 10  global  \n b                      0.847429       5  \n nb                     0.847429       5  \n accuracy               0.847429       5  \n macro avg              0.847429       5  \n weighted avg           0.847429       5  ,\n                            feature importance\n 3  depthfromtopsynset_normalised_x   0.415845\n 4         glosslength_normalised_x   0.167009\n 5                  minwordlength_x   0.116796\n 2          nrpartrels_normalised_x   0.099437\n 8              cabnc_per_100k_2_4m   0.058974\n 1                        nrhypos_x   0.057148\n 7                  polyscore_max_x   0.051378\n 6                     nroflemmas_x   0.030262\n 0                    nrdirhypers_x   0.003151)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'cabnc_per_100k_2_4m'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHILDES: 5.7 million, 2.4 million, 1 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.833333  0.882353  0.857143  17.000000          0.665358   \n nb             0.969231  0.954545  0.961832  66.000000          0.665358   \n accuracy       0.939759  0.939759  0.939759   0.939759          0.665358   \n macro avg      0.901282  0.918449  0.909487  83.000000          0.665358   \n weighted avg   0.941396  0.939759  0.940390  83.000000          0.665358   \n \n               balanced acc / 10  global  \n b                      0.842183       5  \n nb                     0.842183       5  \n accuracy               0.842183       5  \n macro avg              0.842183       5  \n weighted avg           0.842183       5  ,\n                            feature importance\n 3  depthfromtopsynset_normalised_x   0.410704\n 4         glosslength_normalised_x   0.153325\n 8               childes_1m_rel_sum   0.119867\n 5                  minwordlength_x    0.10246\n 2          nrpartrels_normalised_x    0.07224\n 1                        nrhypos_x   0.054912\n 7                  polyscore_max_x   0.051651\n 6                     nroflemmas_x   0.031379\n 0                    nrdirhypers_x   0.003463)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'childes_1m_rel_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.833333  0.882353  0.857143  17.000000          0.669301   \n nb             0.969231  0.954545  0.961832  66.000000          0.669301   \n accuracy       0.939759  0.939759  0.939759   0.939759          0.669301   \n macro avg      0.901282  0.918449  0.909487  83.000000          0.669301   \n weighted avg   0.941396  0.939759  0.940390  83.000000          0.669301   \n \n               balanced acc / 10  global  \n b                      0.843092       5  \n nb                     0.843092       5  \n accuracy               0.843092       5  \n macro avg              0.843092       5  \n weighted avg           0.843092       5  ,\n                            feature importance\n 3  depthfromtopsynset_normalised_x   0.416273\n 4         glosslength_normalised_x   0.160002\n 5                  minwordlength_x   0.113281\n 8             childes_2_4m_rel_sum   0.094002\n 2          nrpartrels_normalised_x   0.071329\n 1                        nrhypos_x    0.05721\n 7                  polyscore_max_x   0.052807\n 6                     nroflemmas_x   0.031834\n 0                    nrdirhypers_x   0.003263)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'childes_2_4m_rel_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.833333  0.882353  0.857143  17.000000          0.673659   \n nb             0.969231  0.954545  0.961832  66.000000          0.673659   \n accuracy       0.939759  0.939759  0.939759   0.939759          0.673659   \n macro avg      0.901282  0.918449  0.909487  83.000000          0.673659   \n weighted avg   0.941396  0.939759  0.940390  83.000000          0.673659   \n \n               balanced acc / 10  global  \n b                      0.844433       5  \n nb                     0.844433       5  \n accuracy               0.844433       5  \n macro avg              0.844433       5  \n weighted avg           0.844433       5  ,\n                            feature importance\n 3  depthfromtopsynset_normalised_x   0.412876\n 4         glosslength_normalised_x   0.158908\n 5                  minwordlength_x   0.115648\n 8             childes_5_7m_rel_sum   0.094229\n 2          nrpartrels_normalised_x   0.073321\n 1                        nrhypos_x   0.057679\n 7                  polyscore_max_x   0.052459\n 6                     nroflemmas_x   0.031432\n 0                    nrdirhypers_x   0.003448)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'childes_5_7m_rel_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BNC: 100 million, 5.7 million, 2.4 million, 1 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.823529  0.823529  0.823529  17.000000          0.687879   \n nb             0.954545  0.954545  0.954545  66.000000          0.687879   \n accuracy       0.927711  0.927711  0.927711   0.927711          0.687879   \n macro avg      0.889037  0.889037  0.889037  83.000000          0.687879   \n weighted avg   0.927711  0.927711  0.927711  83.000000          0.687879   \n \n               balanced acc / 10  global  \n b                      0.846003       5  \n nb                     0.846003       5  \n accuracy               0.846003       5  \n macro avg              0.846003       5  \n weighted avg           0.846003       5  ,\n                            feature importance\n 3  depthfromtopsynset_normalised_x   0.417566\n 4         glosslength_normalised_x    0.15189\n 5                  minwordlength_x   0.128142\n 2          nrpartrels_normalised_x   0.100405\n 1                        nrhypos_x   0.062773\n 8                       bnc_1m_sum   0.055991\n 7                  polyscore_max_x   0.047325\n 6                     nroflemmas_x   0.032886\n 0                    nrdirhypers_x   0.003022)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'bnc_1m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.875000  0.823529  0.848485  17.000000          0.684052   \n nb             0.955224  0.969697  0.962406  66.000000          0.684052   \n accuracy       0.939759  0.939759  0.939759   0.939759          0.684052   \n macro avg      0.915112  0.896613  0.905445  83.000000          0.684052   \n weighted avg   0.938792  0.939759  0.939073  83.000000          0.684052   \n \n               balanced acc / 10  global  \n b                      0.849977       5  \n nb                     0.849977       5  \n accuracy               0.849977       5  \n macro avg              0.849977       5  \n weighted avg           0.849977       5  ,\n                            feature importance\n 3  depthfromtopsynset_normalised_x   0.409364\n 4         glosslength_normalised_x    0.15584\n 5                  minwordlength_x   0.118867\n 2          nrpartrels_normalised_x   0.107318\n 8                     bnc_2_4m_sum   0.068905\n 1                        nrhypos_x    0.06164\n 7                  polyscore_max_x   0.043471\n 6                     nroflemmas_x    0.03175\n 0                    nrdirhypers_x   0.002845)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'bnc_2_4m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['bnc_5_7m_sum'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_46667/43044881.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0msized_corpora\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'bnc_5_7m_sum'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mglobal_model_test\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msized_corpora\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_46667/3012714390.py\u001B[0m in \u001B[0;36mglobal_model_test\u001B[0;34m(dataset, feature, sized_corpora, target)\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mfeature_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfeature\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0msized_corpora\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfeature_list\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3462\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_iterator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3463\u001B[0m                 \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3464\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_listlike_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3465\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3466\u001B[0m         \u001B[0;31m# take() does not accept boolean indexers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m_get_listlike_indexer\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1312\u001B[0m             \u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_indexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reindex_non_unique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1313\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1314\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_read_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1315\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1316\u001B[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m_validate_read_indexer\u001B[0;34m(self, key, indexer, axis)\u001B[0m\n\u001B[1;32m   1375\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1376\u001B[0m             \u001B[0mnot_found\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mensure_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmissing_mask\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnonzero\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1377\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"{not_found} not in index\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1378\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1379\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['bnc_5_7m_sum'] not in index\""
     ]
    }
   ],
   "source": [
    "sized_corpora = 'bnc_5_7m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.833333  0.882353  0.857143  17.000000          0.686256   \n nb             0.969231  0.954545  0.961832  66.000000          0.686256   \n accuracy       0.939759  0.939759  0.939759   0.939759          0.686256   \n macro avg      0.901282  0.918449  0.909487  83.000000          0.686256   \n weighted avg   0.941396  0.939759  0.940390  83.000000          0.686256   \n \n               balanced acc / 10  global  \n b                      0.847429       5  \n nb                     0.847429       5  \n accuracy               0.847429       5  \n macro avg              0.847429       5  \n weighted avg           0.847429       5  ,\n                            feature importance\n 3  depthfromtopsynset_normalised_x    0.38639\n 2          nrpartrels_normalised_x   0.139271\n 4         glosslength_normalised_x   0.137614\n 5                  minwordlength_x   0.107792\n 8                     bnc_100m_sum   0.106636\n 1                        nrhypos_x   0.055014\n 7                  polyscore_max_x   0.036793\n 6                     nroflemmas_x   0.028463\n 0                    nrdirhypers_x   0.002027)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'bnc_100m_sum'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Google Ngram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.777778  0.823529  0.800000  17.000000          0.688993   \n nb             0.953846  0.939394  0.946565  66.000000          0.688993   \n accuracy       0.915663  0.915663  0.915663   0.915663          0.688993   \n macro avg      0.865812  0.881462  0.873282  83.000000          0.688993   \n weighted avg   0.917784  0.915663  0.916546  83.000000          0.688993   \n \n               balanced acc / 10  global  \n b                       0.84584       5  \n nb                      0.84584       5  \n accuracy                0.84584       5  \n macro avg               0.84584       5  \n weighted avg            0.84584       5  ,\n                            feature importance\n 3  depthfromtopsynset_normalised_x   0.418358\n 4         glosslength_normalised_x   0.162561\n 5                  minwordlength_x   0.122179\n 2          nrpartrels_normalised_x   0.077335\n 8     ngram_2009_2019_updata_sleep   0.072726\n 1                        nrhypos_x   0.057108\n 7                  polyscore_max_x    0.05325\n 6                     nroflemmas_x   0.033585\n 0                    nrdirhypers_x   0.002898)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sized_corpora = 'ngram_2009_2019_updata_sleep'\n",
    "global_model_test(data, features, sized_corpora, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: next stage feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                            Synsets domain_x  \\\nnorm                                                           \nadjustable_wrench  Synset('adjustable_wrench.n.01')     tool   \nallen_wrench            Synset('allen_wrench.n.01')     tool   \nalligator_wrench    Synset('alligator_wrench.n.01')     tool   \nawl                              Synset('awl.n.01')     tool   \nbacksaw                      Synset('backsaw.n.01')     tool   \n...                                             ...      ...   \nballet_skirt            Synset('ballet_skirt.n.01')     garm   \nmess_jacket              Synset('mess_jacket.n.01')     garm   \nlong_johns                Synset('long_johns.n.01')     garm   \nundies                        Synset('undies.n.01')     garm   \nlingerie                    Synset('lingerie.n.01')     garm   \n\n                   ngrams_last_mean  nrdirhypers_x  nrhypos_x  \\\nnorm                                                            \nadjustable_wrench        -18.854402              1          7   \nallen_wrench             -18.389126              1          0   \nalligator_wrench         -22.354690              1          0   \nawl                      -14.809997              1          2   \nbacksaw                  -18.327476              1          0   \n...                             ...            ...        ...   \nballet_skirt             -16.872435              1          0   \nmess_jacket              -18.743772              1          0   \nlong_johns               -16.882419              1          0   \nundies                   -16.330160              1          0   \nlingerie                 -15.203406              1          2   \n\n                   nrpartrels_normalised_x  depthfromtopsynset_normalised_x  \\\nnorm                                                                          \nadjustable_wrench                      0.0                         1.012903   \nallen_wrench                           0.0                         1.012903   \nalligator_wrench                       0.0                         1.012903   \nawl                                   15.7                         0.911613   \nbacksaw                                0.0                         1.114194   \n...                                    ...                              ...   \nballet_skirt                           0.0                         0.947552   \nmess_jacket                            0.0                         1.158120   \nlong_johns                             0.0                         1.052836   \nundies                                 0.0                         1.158120   \nlingerie                               0.0                         1.052836   \n\n                   glosslength_normalised_x  minwordlength_x  nroflemmas_x  \\\nnorm                                                                         \nadjustable_wrench                  0.563173               17             2   \nallen_wrench                       0.391092               12             1   \nalligator_wrench                   1.517437               16             1   \nawl                                0.985552                3             1   \nbacksaw                            1.110701                7             2   \n...                                     ...              ...           ...   \nballet_skirt                       0.578283                4             2   \nmess_jacket                        1.652238               11             3   \nlong_johns                         0.479149               10             1   \nundies                             0.280880                6             1   \nlingerie                           0.561761                8             2   \n\n                   ...  min_5_7m min_100m  sum_1m  sum_2_4m  sum_5_7m  \\\nnorm               ...                                                  \nadjustable_wrench  ...         0        0       0         0         0   \nallen_wrench       ...         0        0       0         0         0   \nalligator_wrench   ...         0        0       0         0         0   \nawl                ...         0       39       1         1         3   \nbacksaw            ...         0        0       0         0         0   \n...                ...       ...      ...     ...       ...       ...   \nballet_skirt       ...         0       33       0         0         1   \nmess_jacket        ...         0        0       0         0         0   \nlong_johns         ...         0        0       0         0         0   \nundies             ...         0       33       1         1         1   \nlingerie           ...         0       67       1         1         1   \n\n                   sum_100m  avg_bnc  avg_childes  avg_cabnc  avg_kbnc  \nnorm                                                                    \nadjustable_wrench         0     0.00     0.000000        0.0       0.0  \nallen_wrench              0     0.00     0.000000        0.0       0.0  \nalligator_wrench          0     0.00     0.000000        0.0       0.0  \nawl                      39    11.00     0.000000        0.0       0.0  \nbacksaw                   0     0.00     0.000000        0.0       0.0  \n...                     ...      ...          ...        ...       ...  \nballet_skirt             33     8.25     0.333333        0.0       0.0  \nmess_jacket               0     0.00     0.000000        0.0       0.0  \nlong_johns                0     0.00     0.000000        0.0       0.0  \nundies                   33     9.00     0.000000        0.0       0.0  \nlingerie                 67    17.50     0.000000        0.0       0.0  \n\n[839 rows x 43 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Synsets</th>\n      <th>domain_x</th>\n      <th>ngrams_last_mean</th>\n      <th>nrdirhypers_x</th>\n      <th>nrhypos_x</th>\n      <th>nrpartrels_normalised_x</th>\n      <th>depthfromtopsynset_normalised_x</th>\n      <th>glosslength_normalised_x</th>\n      <th>minwordlength_x</th>\n      <th>nroflemmas_x</th>\n      <th>...</th>\n      <th>min_5_7m</th>\n      <th>min_100m</th>\n      <th>sum_1m</th>\n      <th>sum_2_4m</th>\n      <th>sum_5_7m</th>\n      <th>sum_100m</th>\n      <th>avg_bnc</th>\n      <th>avg_childes</th>\n      <th>avg_cabnc</th>\n      <th>avg_kbnc</th>\n    </tr>\n    <tr>\n      <th>norm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>adjustable_wrench</th>\n      <td>Synset('adjustable_wrench.n.01')</td>\n      <td>tool</td>\n      <td>-18.854402</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.563173</td>\n      <td>17</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>allen_wrench</th>\n      <td>Synset('allen_wrench.n.01')</td>\n      <td>tool</td>\n      <td>-18.389126</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.391092</td>\n      <td>12</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>alligator_wrench</th>\n      <td>Synset('alligator_wrench.n.01')</td>\n      <td>tool</td>\n      <td>-22.354690</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>1.517437</td>\n      <td>16</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>awl</th>\n      <td>Synset('awl.n.01')</td>\n      <td>tool</td>\n      <td>-14.809997</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15.7</td>\n      <td>0.911613</td>\n      <td>0.985552</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>39</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>39</td>\n      <td>11.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>backsaw</th>\n      <td>Synset('backsaw.n.01')</td>\n      <td>tool</td>\n      <td>-18.327476</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.114194</td>\n      <td>1.110701</td>\n      <td>7</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>ballet_skirt</th>\n      <td>Synset('ballet_skirt.n.01')</td>\n      <td>garm</td>\n      <td>-16.872435</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.947552</td>\n      <td>0.578283</td>\n      <td>4</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>33</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>33</td>\n      <td>8.25</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>mess_jacket</th>\n      <td>Synset('mess_jacket.n.01')</td>\n      <td>garm</td>\n      <td>-18.743772</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>1.652238</td>\n      <td>11</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>long_johns</th>\n      <td>Synset('long_johns.n.01')</td>\n      <td>garm</td>\n      <td>-16.882419</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.479149</td>\n      <td>10</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>undies</th>\n      <td>Synset('undies.n.01')</td>\n      <td>garm</td>\n      <td>-16.330160</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>0.280880</td>\n      <td>6</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>33</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>33</td>\n      <td>9.00</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>lingerie</th>\n      <td>Synset('lingerie.n.01')</td>\n      <td>garm</td>\n      <td>-15.203406</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.561761</td>\n      <td>8</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>67</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>67</td>\n      <td>17.50</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>839 rows × 43 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "# read the pre-processed data all agreed\ndata = pd.read_csv('./next_stage_size_differential_features.csv', index_col=0)\n\n# generate the local dataframe for different domains\nlocal_fruit = data.loc[data['domain_x']=='fruit'].reset_index()\nlocal_tool = data.loc[data['domain_x']=='tool'].reset_index()\nlocal_music = data.loc[data['domain_x']=='music'].reset_index()\nlocal_furniture = data.loc[data['domain_x']=='furn'].reset_index()\nlocal_garments = data.loc[data['domain_x']=='garm'].reset_index()\n\ndata"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": "# split training set and testing set using K-Flod\ndef new_features_global_model_test(dataset, feature, new_features, target):\n    K = 10\n    random_seed = 7 # R\n    data = dataset.reset_index()\n    feature_list = feature + new_features\n    X = data[feature_list]\n    y = data[target]\n\n    K_Flod = StratifiedKFold(n_splits=K, shuffle=True, random_state=random_seed)\n    K_Flod.get_n_splits(X, y)\n    cohen_kappa = []\n    balanced_acc = []\n    for train_index, test_index in K_Flod.split(X, y):\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n        # SMOTE algorithm\n        smote = SMOTE(random_state=random_seed, k_neighbors=2)\n        X_train, y_train = smote.fit_resample(X_train, y_train)\n\n        # define random forest model\n        rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n\n        # predict and make score\n        pipeline = make_pipeline(smote, rf)\n        y_pred = pipeline.predict(X_test)\n\n        kappa = cohen_kappa_score(y_test, y_pred)\n        cohen_kappa.append(kappa)\n        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n        balanced_acc.append(balanced_accuracy)\n\n    results = classification_report(y_test, y_pred, output_dict=True)\n    results = pd.DataFrame(results).transpose()\n\n    results['cohen kappa / 10'] = np.mean(cohen_kappa)\n    results['balanced acc / 10'] = np.mean(balanced_acc)\n    results['global'] = 5\n\n    # importance of features\n    importance = rf.feature_importances_\n    importance = pd.DataFrame([feature_list, importance]).transpose()\n    importance = importance.rename(columns={0:'feature', 1:'importance'}).sort_values('importance', ascending=False)\n\n    return results, importance"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## feature selection"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.823529  0.823529  0.823529  17.000000          0.638242   \n nb             0.954545  0.954545  0.954545  66.000000          0.638242   \n accuracy       0.927711  0.927711  0.927711   0.927711          0.638242   \n macro avg      0.889037  0.889037  0.889037  83.000000          0.638242   \n weighted avg   0.927711  0.927711  0.927711  83.000000          0.638242   \n \n               balanced acc / 10  global  \n b                      0.831217       5  \n nb                     0.831217       5  \n accuracy               0.831217       5  \n macro avg              0.831217       5  \n weighted avg           0.831217       5  ,\n                             feature importance\n 3   depthfromtopsynset_normalised_x   0.276916\n 4          glosslength_normalised_x   0.111362\n 2           nrpartrels_normalised_x    0.10688\n 5                   minwordlength_x    0.07629\n 20                          avg_bnc   0.038162\n 19                         sum_100m   0.037684\n 15                         min_100m   0.036771\n 11                         max_100m   0.036664\n 1                         nrhypos_x   0.032532\n 23                         avg_kbnc   0.031644\n 21                      avg_childes    0.03115\n 6                      nroflemmas_x   0.022683\n 7                   polyscore_max_x   0.020905\n 8                            max_1m   0.019034\n 18                         sum_5_7m   0.018629\n 10                         max_5_7m   0.018328\n 16                           sum_1m   0.018233\n 17                         sum_2_4m   0.014161\n 9                          max_2_4m   0.013768\n 22                        avg_cabnc   0.012314\n 14                         min_5_7m   0.010923\n 13                         min_2_4m   0.007857\n 12                           min_1m   0.005437\n 0                     nrdirhypers_x   0.001675)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "# top-down method\nnew_feature = ['max_1m','max_2_4m','max_5_7m','max_100m','min_1m','min_2_4m','min_5_7m','min_100m','sum_1m','sum_2_4m','sum_5_7m','sum_100m','avg_bnc','avg_childes','avg_cabnc','avg_kbnc']\nnew_features_global_model_test(data, features, new_feature, target)"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(              precision    recall  f1-score    support  cohen kappa / 10  \\\n b              0.875000  0.823529  0.848485  17.000000          0.642998   \n nb             0.955224  0.969697  0.962406  66.000000          0.642998   \n accuracy       0.939759  0.939759  0.939759   0.939759          0.642998   \n macro avg      0.915112  0.896613  0.905445  83.000000          0.642998   \n weighted avg   0.938792  0.939759  0.939073  83.000000          0.642998   \n \n               balanced acc / 10  global  \n b                      0.830526       5  \n nb                     0.830526       5  \n accuracy               0.830526       5  \n macro avg              0.830526       5  \n weighted avg           0.830526       5  ,\n                             feature importance\n 3   depthfromtopsynset_normalised_x   0.280757\n 4          glosslength_normalised_x   0.116417\n 2           nrpartrels_normalised_x   0.104133\n 5                   minwordlength_x   0.075361\n 18                         sum_100m   0.037152\n 19                          avg_bnc   0.036779\n 14                         min_100m   0.036392\n 11                         max_100m   0.036023\n 22                         avg_kbnc   0.034424\n 1                         nrhypos_x    0.03214\n 20                      avg_childes   0.031818\n 6                      nroflemmas_x   0.022381\n 7                   polyscore_max_x    0.02103\n 17                         sum_5_7m   0.019475\n 15                           sum_1m    0.01898\n 10                         max_5_7m     0.0182\n 8                            max_1m   0.017077\n 16                         sum_2_4m    0.01482\n 9                          max_2_4m   0.013602\n 21                        avg_cabnc   0.012412\n 13                         min_5_7m   0.011601\n 12                         min_2_4m   0.007334\n 0                     nrdirhypers_x   0.001693)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "# remove min_1m\nnew_feature = ['max_1m','max_2_4m','max_5_7m','max_100m','min_2_4m','min_5_7m','min_100m','sum_1m','sum_2_4m','sum_5_7m','sum_100m','avg_bnc','avg_childes','avg_cabnc','avg_kbnc']\nnew_features_global_model_test(data, features, new_feature, target)"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "feature: max_1m\n0.6992007014562882\nmax_1m\n              precision    recall  f1-score    support  cohen kappa / 10  \\\nb              0.882353  0.882353  0.882353  17.000000          0.699201   \nnb             0.969697  0.969697  0.969697  66.000000          0.699201   \naccuracy       0.951807  0.951807  0.951807   0.951807          0.699201   \nmacro avg      0.926025  0.926025  0.926025  83.000000          0.699201   \nweighted avg   0.951807  0.951807  0.951807  83.000000          0.699201   \n\n              balanced acc / 10  global  \nb                      0.857515       5  \nnb                     0.857515       5  \naccuracy               0.857515       5  \nmacro avg              0.857515       5  \nweighted avg           0.857515       5  \n                           feature importance\n3  depthfromtopsynset_normalised_x   0.361696\n4         glosslength_normalised_x   0.134097\n2          nrpartrels_normalised_x   0.132681\n5                  minwordlength_x   0.105417\n8                     bnc_100m_sum   0.095006\n9                           max_1m   0.056525\n1                        nrhypos_x      0.053\n7                  polyscore_max_x   0.032077\n6                     nroflemmas_x   0.027593\n0                    nrdirhypers_x   0.001909\nfeature: max_2_4m\nfeature: max_5_7m\nfeature: max_100m\n0.7046320030499714\nmax_100m\n              precision    recall  f1-score    support  cohen kappa / 10  \\\nb              0.833333  0.882353  0.857143  17.000000          0.704632   \nnb             0.969231  0.954545  0.961832  66.000000          0.704632   \naccuracy       0.939759  0.939759  0.939759   0.939759          0.704632   \nmacro avg      0.901282  0.918449  0.909487  83.000000          0.704632   \nweighted avg   0.941396  0.939759  0.940390  83.000000          0.704632   \n\n              balanced acc / 10  global  \nb                      0.857255       5  \nnb                     0.857255       5  \naccuracy               0.857255       5  \nmacro avg              0.857255       5  \nweighted avg           0.857255       5  \n                           feature importance\n3  depthfromtopsynset_normalised_x     0.3549\n2          nrpartrels_normalised_x   0.137371\n4         glosslength_normalised_x   0.133698\n5                  minwordlength_x   0.106087\n9                         max_100m   0.080046\n8                     bnc_100m_sum   0.078455\n1                        nrhypos_x   0.049025\n7                  polyscore_max_x    0.03043\n6                     nroflemmas_x   0.028036\n0                    nrdirhypers_x   0.001952\nfeature: min_1m\nfeature: min_2_4m\nfeature: min_5_7m\nfeature: min_100m\nfeature: sum_1m\nfeature: sum_2_4m\nfeature: sum_5_7m\nfeature: sum_100m\nfeature: avg_bnc\n0.7061738296136519\navg_bnc\n              precision    recall  f1-score    support  cohen kappa / 10  \\\nb              0.842105  0.941176  0.888889  17.000000          0.706174   \nnb             0.984375  0.954545  0.969231  66.000000          0.706174   \naccuracy       0.951807  0.951807  0.951807   0.951807          0.706174   \nmacro avg      0.913240  0.947861  0.929060  83.000000          0.706174   \nweighted avg   0.955235  0.951807  0.952775  83.000000          0.706174   \n\n              balanced acc / 10  global  \nb                       0.85945       5  \nnb                      0.85945       5  \naccuracy                0.85945       5  \nmacro avg               0.85945       5  \nweighted avg            0.85945       5  \n                           feature importance\n3  depthfromtopsynset_normalised_x   0.363867\n2          nrpartrels_normalised_x   0.136777\n4         glosslength_normalised_x   0.131012\n5                  minwordlength_x   0.099053\n9                          avg_bnc   0.079348\n8                     bnc_100m_sum   0.079308\n1                        nrhypos_x   0.051071\n7                  polyscore_max_x   0.030956\n6                     nroflemmas_x    0.02645\n0                    nrdirhypers_x   0.002157\nfeature: avg_childes\nfeature: avg_cabnc\nfeature: avg_kbnc\n"
    }
   ],
   "source": "# bottom-up method +1\nnew_feature = ['max_1m','max_2_4m','max_5_7m','max_100m','min_1m','min_2_4m','min_5_7m','min_100m','sum_1m','sum_2_4m','sum_5_7m','sum_100m','avg_bnc','avg_childes','avg_cabnc','avg_kbnc']\nmax_kappa = 0\nfor i in new_feature:\n    print(\"feature: \" + i)\n    new = ['bnc_100m_sum'] + [i]\n    res, f_importance = new_features_global_model_test(data, features, new, target)\n    if res['cohen kappa / 10'][0] > max_kappa:\n        max_kappa = res['cohen kappa / 10'][0]\n        print(max_kappa)\n        print(i)\n        print(res)\n        print(f_importance)"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "feature: max_1m\n0.7079283480806089\nmax_1m\n              precision    recall  f1-score    support  cohen kappa / 10  \\\nb              0.888889  0.941176  0.914286  17.000000          0.707928   \nnb             0.984615  0.969697  0.977099  66.000000          0.707928   \naccuracy       0.963855  0.963855  0.963855   0.963855          0.707928   \nmacro avg      0.936752  0.955437  0.945692  83.000000          0.707928   \nweighted avg   0.965009  0.963855  0.964234  83.000000          0.707928   \n\n              balanced acc / 10  global  \nb                      0.865277       5  \nnb                     0.865277       5  \naccuracy               0.865277       5  \nmacro avg              0.865277       5  \nweighted avg           0.865277       5  \n                            feature importance\n3   depthfromtopsynset_normalised_x   0.335542\n2           nrpartrels_normalised_x   0.131624\n4          glosslength_normalised_x   0.130683\n5                   minwordlength_x   0.099291\n8                      bnc_100m_sum   0.075602\n9                           avg_bnc   0.072155\n1                         nrhypos_x   0.051049\n10                           max_1m   0.045306\n7                   polyscore_max_x   0.029888\n6                      nroflemmas_x   0.026922\n0                     nrdirhypers_x   0.001938\nfeature: max_2_4m\nfeature: max_5_7m\nfeature: max_100m\nfeature: min_2_4m\nfeature: min_5_7m\nfeature: min_100m\nfeature: sum_1m\nfeature: sum_2_4m\nfeature: sum_5_7m\nfeature: sum_100m\nfeature: avg_childes\nfeature: avg_cabnc\nfeature: avg_kbnc\n"
    }
   ],
   "source": "# bottom-up method +2 (base: avg_bnc)\nnew_feature = ['max_1m', 'max_2_4m','max_5_7m','max_100m','min_2_4m','min_5_7m','min_100m','sum_1m','sum_2_4m','sum_5_7m','sum_100m','avg_childes','avg_cabnc','avg_kbnc']\nmax_kappa = 0.706174\nfor i in new_feature:\n    print(\"feature: \" + i)\n    new = ['bnc_100m_sum', 'avg_bnc'] + [i]\n    res, f_importance = new_features_global_model_test(data, features, new, target)\n    if res['cohen kappa / 10'][0] > max_kappa:\n        max_kappa = res['cohen kappa / 10'][0]\n        print(max_kappa)\n        print(i)\n        print(res)\n        print(f_importance)"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "feature: max_2_4m\nfeature: max_5_7m\nfeature: max_100m\nfeature: min_2_4m\nfeature: min_5_7m\nfeature: min_100m\nfeature: sum_1m\nfeature: sum_2_4m\nfeature: sum_5_7m\nfeature: sum_100m\nfeature: avg_childes\nfeature: avg_cabnc\nfeature: avg_kbnc\n"
    }
   ],
   "source": "# bottom-up method +3 (base: avg_bnc, max_1m)\nnew_feature = ['max_2_4m','max_5_7m','max_100m','min_2_4m','min_5_7m','min_100m','sum_1m','sum_2_4m','sum_5_7m','sum_100m','avg_childes','avg_cabnc','avg_kbnc']\nmax_kappa = 0.707928\nfor i in new_feature:\n    print(\"feature: \" + i)\n    new = ['bnc_100m_sum', 'avg_bnc', 'max_1m'] + [i]\n    res, f_importance = new_features_global_model_test(data, features, new, target)\n    if res['cohen kappa / 10'][0] > max_kappa:\n        max_kappa = res['cohen kappa / 10'][0]\n        print(max_kappa)\n        print(i)\n        print(res)\n        print(f_importance)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}