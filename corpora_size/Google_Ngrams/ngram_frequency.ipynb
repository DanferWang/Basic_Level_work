{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "trusted": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import nltk\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# only once run for download WordNet or update\n",
    "import nltk\n",
    "# nltk.download('wordnet', download_dir='./')\n",
    "nltk.data.path.append('../')\n",
    "from nltk.corpus import wordnet as wn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                              Synsets domain_x  nrdirhypers_x  nrhypos_x  \\\n0    Synset('adjustable_wrench.n.01')     tool              1          7   \n1         Synset('allen_wrench.n.01')     tool              1          0   \n2     Synset('alligator_wrench.n.01')     tool              1          0   \n3                  Synset('awl.n.01')     tool              1          2   \n4              Synset('backsaw.n.01')     tool              1          0   \n..                                ...      ...            ...        ...   \n834       Synset('ballet_skirt.n.01')     garm              1          0   \n835        Synset('mess_jacket.n.01')     garm              1          0   \n836         Synset('long_johns.n.01')     garm              1          0   \n837             Synset('undies.n.01')     garm              1          0   \n838           Synset('lingerie.n.01')     garm              1          2   \n\n     nrpartrels_normalised_x  depthfromtopsynset_normalised_x  \\\n0                        0.0                         1.012903   \n1                        0.0                         1.012903   \n2                        0.0                         1.012903   \n3                       15.7                         0.911613   \n4                        0.0                         1.114194   \n..                       ...                              ...   \n834                      0.0                         0.947552   \n835                      0.0                         1.158120   \n836                      0.0                         1.052836   \n837                      0.0                         1.158120   \n838                      0.0                         1.052836   \n\n     glosslength_normalised_x  minwordlength_x  nroflemmas_x  polyscore_max_x  \\\n0                    0.563173               17             2                1   \n1                    0.391092               12             1                1   \n2                    1.517437               16             1                1   \n3                    0.985552                3             1                1   \n4                    1.110701                7             2                1   \n..                        ...              ...           ...              ...   \n834                  0.578283                4             2                2   \n835                  1.652238               11             3                1   \n836                  0.479149               10             1                1   \n837                  0.280880                6             1                1   \n838                  0.561761                8             2                1   \n\n    vote_x  \n0       nb  \n1       nb  \n2       nb  \n3        b  \n4       nb  \n..     ...  \n834     nb  \n835     nb  \n836     nb  \n837     nb  \n838     nb  \n\n[839 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Synsets</th>\n      <th>domain_x</th>\n      <th>nrdirhypers_x</th>\n      <th>nrhypos_x</th>\n      <th>nrpartrels_normalised_x</th>\n      <th>depthfromtopsynset_normalised_x</th>\n      <th>glosslength_normalised_x</th>\n      <th>minwordlength_x</th>\n      <th>nroflemmas_x</th>\n      <th>polyscore_max_x</th>\n      <th>vote_x</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Synset('adjustable_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.563173</td>\n      <td>17</td>\n      <td>2</td>\n      <td>1</td>\n      <td>nb</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Synset('allen_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.391092</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Synset('alligator_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>1.517437</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Synset('awl.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15.7</td>\n      <td>0.911613</td>\n      <td>0.985552</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Synset('backsaw.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.114194</td>\n      <td>1.110701</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n      <td>nb</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>834</th>\n      <td>Synset('ballet_skirt.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.947552</td>\n      <td>0.578283</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>nb</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>Synset('mess_jacket.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>1.652238</td>\n      <td>11</td>\n      <td>3</td>\n      <td>1</td>\n      <td>nb</td>\n    </tr>\n    <tr>\n      <th>836</th>\n      <td>Synset('long_johns.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.479149</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n    </tr>\n    <tr>\n      <th>837</th>\n      <td>Synset('undies.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>0.280880</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n    </tr>\n    <tr>\n      <th>838</th>\n      <td>Synset('lingerie.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.561761</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>nb</td>\n    </tr>\n  </tbody>\n</table>\n<p>839 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inherit features from Gold Standard dataset\n",
    "GS_all_agreed = pd.read_csv('../sampled_count/GS_All_Agreed.csv', index_col=0)\n",
    "features_target = ['Synsets','domain_x',\n",
    "                   'nrdirhypers_x',\n",
    "                   'nrhypos_x',\n",
    "                   'nrpartrels_normalised_x',\n",
    "                   'depthfromtopsynset_normalised_x',\n",
    "                   'glosslength_normalised_x',\n",
    "                   'minwordlength_x',\n",
    "                   'nroflemmas_x',\n",
    "                   'polyscore_max_x',\n",
    "                   'vote_x']\n",
    "GS_adopt = GS_all_agreed[features_target]\n",
    "\n",
    "GS_adopt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# function to get the frequency of a synset in google ngrams\n",
    "corpora = dict(eng_2019=26, eng_us_2012=17, eng_us_2009=5, eng_gb_2012=18, eng_gb_2009=6,\n",
    "               chi_sim_2012=23, chi_sim_2009=11, eng_2012=15, eng_2009=0,\n",
    "               eng_fiction_2012=16, eng_fiction_2009=4, eng_1m_2009=1,\n",
    "               fre_2012=19, fre_2009=7, ger_2012=20, ger_2009=8, heb_2012=24,\n",
    "               heb_2009=9, spa_2012=21, spa_2009=10, rus_2012=25, rus_2009=12,\n",
    "               ita_2012=22)\n",
    "def ngram_mean_by_year_sleep(synset, corpus, startYear, endYear, smoothing, caseInsensitive):\n",
    "    global counter\n",
    "    m = 0\n",
    "    synset = wn.synset(synset[8:-2])\n",
    "    for i in synset.lemmas():\n",
    "        query = i.name()\n",
    "        query = query.replace('_',' ') # recovery phrase from _\n",
    "        params = dict(content=query, year_start=startYear, year_end=endYear,\n",
    "                      corpus=corpora[corpus], smoothing=smoothing,\n",
    "                      case_insensitive=caseInsensitive)\n",
    "        if params['case_insensitive'] is False:\n",
    "            params.pop('case_insensitive')\n",
    "        if '?' in params['content']:\n",
    "            params['content'] = params['content'].replace('?', '*')\n",
    "        if '@' in params['content']:\n",
    "            params['content'] = params['content'].replace('@', '=>')\n",
    "        ## set a counter\n",
    "        counter += 1\n",
    "        if counter == 73:\n",
    "            time.sleep(580)\n",
    "            counter = 0\n",
    "        req = requests.get('https://books.google.com/ngrams/graph', params=params)\n",
    "        res = re.findall('ngrams.data = (.*?);\\\\n', req.text)\n",
    "        if res:\n",
    "            data = {qry['ngram']: qry['timeseries'] for qry in literal_eval(res[0])}\n",
    "            df = pd.DataFrame(data)\n",
    "            df.insert(0, 'year', list(range(startYear, endYear + 1)))\n",
    "        else:\n",
    "            df = pd.DataFrame()\n",
    "        if df.shape[1] > 1: # if the query exists in google ngrams.\n",
    "            ngramsum = df.iloc[:,1].sum(axis = 0, skipna = True) # sum of percentage of the lemmas each year\n",
    "            # time.sleep(10) # to avoid defense from the google ngram server\n",
    "            m += ngramsum\n",
    "        else:\n",
    "            m += 0 # irrelevant, obviously.\n",
    "    return m/(endYear-startYear+1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "2.8056081676068473e-07"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "ngram_mean_by_year_sleep(\"Synset('awl.n.01')\", 'eng_2019', 2009, 2019, 0, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_102908/3909229814.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mGS_adopt\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'ngram_2009_2019'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGS_adopt\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Synsets'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0msyn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mngram_mean_by_year_sleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msyn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'eng_2019'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2009\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2019\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mGS_adopt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[1;32m   4355\u001B[0m         \u001B[0mdtype\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mfloat64\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4356\u001B[0m         \"\"\"\n\u001B[0;32m-> 4357\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mSeriesApply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconvert_dtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4358\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4359\u001B[0m     def _reduce(\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1041\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_str\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1042\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1043\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1044\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1045\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0magg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1096\u001B[0m                 \u001B[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1097\u001B[0m                 \u001B[0;31m# \"Callable[[Any], Any]\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1098\u001B[0;31m                 mapped = lib.map_infer(\n\u001B[0m\u001B[1;32m   1099\u001B[0m                     \u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1100\u001B[0m                     \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;31m# type: ignore[arg-type]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_102908/3909229814.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(syn)\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mGS_adopt\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'ngram_2009_2019'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGS_adopt\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Synsets'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0msyn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mngram_mean_by_year_sleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msyn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'eng_2019'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2009\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2019\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mGS_adopt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_102908/1020123345.py\u001B[0m in \u001B[0;36mngram_mean_by_year_sleep\u001B[0;34m(synset, corpus, startYear, endYear, smoothing, caseInsensitive)\u001B[0m\n\u001B[1;32m     37\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# if the query exists in google ngrams.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m             \u001B[0mngramsum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskipna\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# sum of percentage of the lemmas each year\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 39\u001B[0;31m             \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# to avoid defense from the google ngram server\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     40\u001B[0m             \u001B[0mm\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mngramsum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "GS_adopt['ngram_2009_2019'] = GS_adopt['Synsets'].apply(lambda syn: ngram_mean_by_year_sleep(syn, 'eng_2019', 2009, 2019, 0, True))\n",
    "\n",
    "GS_adopt.to_csv('./features_google_ngram.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def ngram_mean_by_year(synset, corpus, startYear, endYear, smoothing, caseInsensitive):\n",
    "    m = 0\n",
    "    synset = wn.synset(synset[8:-2])\n",
    "    for i in synset.lemmas():\n",
    "        query = i.name()\n",
    "        query = query.replace('_', ' ')  # recovery phrase from _\n",
    "        params = dict(content=query, year_start=startYear, year_end=endYear,\n",
    "                      corpus=corpora[corpus], smoothing=smoothing,\n",
    "                      case_insensitive=caseInsensitive)\n",
    "        if params['case_insensitive'] is False:\n",
    "            params.pop('case_insensitive')\n",
    "        if '?' in params['content']:\n",
    "            params['content'] = params['content'].replace('?', '*')\n",
    "        if '@' in params['content']:\n",
    "            params['content'] = params['content'].replace('@', '=>')\n",
    "        req = requests.get('https://books.google.com/ngrams/graph', params=params)\n",
    "        res = re.findall('ngrams.data = (.*?);\\\\n', req.text)\n",
    "        if res:\n",
    "            data = {qry['ngram']: qry['timeseries'] for qry in literal_eval(res[0])}\n",
    "            df = pd.DataFrame(data)\n",
    "            df.insert(0, 'year', list(range(startYear, endYear + 1)))\n",
    "        else:\n",
    "            df = pd.DataFrame()\n",
    "        if df.shape[1] > 1:  # if the query exists in google ngrams.\n",
    "            ngramsum = df.iloc[:, 1].sum(axis=0, skipna=True)  # sum of percentage of the lemmas each year\n",
    "            time.sleep(10)  # to avoid defense from the google ngram server\n",
    "            m += ngramsum\n",
    "        else:\n",
    "            m += 0  # irrelevant, obviously.\n",
    "    return m / (endYear - startYear + 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check time\n",
    "# original\n",
    "original_start = time.time()\n",
    "GS_adopt['ngram_2009_2019_original_sleep'] = GS_adopt['Synsets'].apply(lambda syn: ngram_mean_by_year(syn, 'eng_2019', 2009, 2019, 0, True))\n",
    "original_stop = time.time()\n",
    "original_period = original_stop - original_start\n",
    "\n",
    "string = 'original sleep time is ' + str(original_period) + '\\n'\n",
    "with open('time_checker.txt', 'a+') as f:\n",
    "    f.write(string)\n",
    "\n",
    "time.sleep(580)\n",
    "update_start = time.time()\n",
    "counter = 0\n",
    "GS_adopt['ngram_2009_2019_updata_sleep'] = GS_adopt['Synsets'].apply(lambda syn: ngram_mean_by_year_sleep(syn, 'eng_2019', 2009, 2019, 0, True))\n",
    "update_stop = time.time()\n",
    "update_period = update_stop - update_start\n",
    "string = 'update sleep time is ' + str(update_period) + '\\n'\n",
    "with open('time_checker.txt', 'a+') as f:\n",
    "    f.write(string)\n",
    "\n",
    "GS_adopt.to_csv('./features_google_ngram.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 domain_x  nrdirhypers_x  nrhypos_x  \\\nSynsets                                                               \nSynset('adjustable_wrench.n.01')     tool              1          7   \nSynset('allen_wrench.n.01')          tool              1          0   \nSynset('alligator_wrench.n.01')      tool              1          0   \nSynset('awl.n.01')                   tool              1          2   \nSynset('backsaw.n.01')               tool              1          0   \n...                                   ...            ...        ...   \nSynset('ballet_skirt.n.01')          garm              1          0   \nSynset('mess_jacket.n.01')           garm              1          0   \nSynset('long_johns.n.01')            garm              1          0   \nSynset('undies.n.01')                garm              1          0   \nSynset('lingerie.n.01')              garm              1          2   \n\n                                  nrpartrels_normalised_x  \\\nSynsets                                                     \nSynset('adjustable_wrench.n.01')                      0.0   \nSynset('allen_wrench.n.01')                           0.0   \nSynset('alligator_wrench.n.01')                       0.0   \nSynset('awl.n.01')                                   15.7   \nSynset('backsaw.n.01')                                0.0   \n...                                                   ...   \nSynset('ballet_skirt.n.01')                           0.0   \nSynset('mess_jacket.n.01')                            0.0   \nSynset('long_johns.n.01')                             0.0   \nSynset('undies.n.01')                                 0.0   \nSynset('lingerie.n.01')                               0.0   \n\n                                  depthfromtopsynset_normalised_x  \\\nSynsets                                                             \nSynset('adjustable_wrench.n.01')                         1.012903   \nSynset('allen_wrench.n.01')                              1.012903   \nSynset('alligator_wrench.n.01')                          1.012903   \nSynset('awl.n.01')                                       0.911613   \nSynset('backsaw.n.01')                                   1.114194   \n...                                                           ...   \nSynset('ballet_skirt.n.01')                              0.947552   \nSynset('mess_jacket.n.01')                               1.158120   \nSynset('long_johns.n.01')                                1.052836   \nSynset('undies.n.01')                                    1.158120   \nSynset('lingerie.n.01')                                  1.052836   \n\n                                  glosslength_normalised_x  minwordlength_x  \\\nSynsets                                                                       \nSynset('adjustable_wrench.n.01')                  0.563173               17   \nSynset('allen_wrench.n.01')                       0.391092               12   \nSynset('alligator_wrench.n.01')                   1.517437               16   \nSynset('awl.n.01')                                0.985552                3   \nSynset('backsaw.n.01')                            1.110701                7   \n...                                                    ...              ...   \nSynset('ballet_skirt.n.01')                       0.578283                4   \nSynset('mess_jacket.n.01')                        1.652238               11   \nSynset('long_johns.n.01')                         0.479149               10   \nSynset('undies.n.01')                             0.280880                6   \nSynset('lingerie.n.01')                           0.561761                8   \n\n                                  nroflemmas_x  polyscore_max_x vote_x  \\\nSynsets                                                                  \nSynset('adjustable_wrench.n.01')             2                1     nb   \nSynset('allen_wrench.n.01')                  1                1     nb   \nSynset('alligator_wrench.n.01')              1                1     nb   \nSynset('awl.n.01')                           1                1      b   \nSynset('backsaw.n.01')                       2                1     nb   \n...                                        ...              ...    ...   \nSynset('ballet_skirt.n.01')                  2                2     nb   \nSynset('mess_jacket.n.01')                   3                1     nb   \nSynset('long_johns.n.01')                    1                1     nb   \nSynset('undies.n.01')                        1                1     nb   \nSynset('lingerie.n.01')                      2                1     nb   \n\n                                  ngram_2009_2019_original_sleep  \\\nSynsets                                                            \nSynset('adjustable_wrench.n.01')                    2.460615e-08   \nSynset('allen_wrench.n.01')                         1.601034e-08   \nSynset('alligator_wrench.n.01')                     1.236022e-10   \nSynset('awl.n.01')                                  2.805608e-07   \nSynset('backsaw.n.01')                              1.135172e-08   \n...                                                          ...   \nSynset('ballet_skirt.n.01')                         5.498723e-07   \nSynset('mess_jacket.n.01')                          1.454007e-08   \nSynset('long_johns.n.01')                           8.935307e-08   \nSynset('undies.n.01')                               2.118603e-07   \nSynset('lingerie.n.01')                             9.058988e-07   \n\n                                  ngram_2009_2019_updata_sleep  \nSynsets                                                         \nSynset('adjustable_wrench.n.01')                  2.460615e-08  \nSynset('allen_wrench.n.01')                       1.601034e-08  \nSynset('alligator_wrench.n.01')                   1.236022e-10  \nSynset('awl.n.01')                                2.805608e-07  \nSynset('backsaw.n.01')                            1.135172e-08  \n...                                                        ...  \nSynset('ballet_skirt.n.01')                       5.498723e-07  \nSynset('mess_jacket.n.01')                        1.454007e-08  \nSynset('long_johns.n.01')                         8.935307e-08  \nSynset('undies.n.01')                             2.118603e-07  \nSynset('lingerie.n.01')                           9.058988e-07  \n\n[839 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>domain_x</th>\n      <th>nrdirhypers_x</th>\n      <th>nrhypos_x</th>\n      <th>nrpartrels_normalised_x</th>\n      <th>depthfromtopsynset_normalised_x</th>\n      <th>glosslength_normalised_x</th>\n      <th>minwordlength_x</th>\n      <th>nroflemmas_x</th>\n      <th>polyscore_max_x</th>\n      <th>vote_x</th>\n      <th>ngram_2009_2019_original_sleep</th>\n      <th>ngram_2009_2019_updata_sleep</th>\n    </tr>\n    <tr>\n      <th>Synsets</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Synset('adjustable_wrench.n.01')</th>\n      <td>tool</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.563173</td>\n      <td>17</td>\n      <td>2</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>2.460615e-08</td>\n      <td>2.460615e-08</td>\n    </tr>\n    <tr>\n      <th>Synset('allen_wrench.n.01')</th>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.391092</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>1.601034e-08</td>\n      <td>1.601034e-08</td>\n    </tr>\n    <tr>\n      <th>Synset('alligator_wrench.n.01')</th>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>1.517437</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>1.236022e-10</td>\n      <td>1.236022e-10</td>\n    </tr>\n    <tr>\n      <th>Synset('awl.n.01')</th>\n      <td>tool</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15.7</td>\n      <td>0.911613</td>\n      <td>0.985552</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>b</td>\n      <td>2.805608e-07</td>\n      <td>2.805608e-07</td>\n    </tr>\n    <tr>\n      <th>Synset('backsaw.n.01')</th>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.114194</td>\n      <td>1.110701</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>1.135172e-08</td>\n      <td>1.135172e-08</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Synset('ballet_skirt.n.01')</th>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.947552</td>\n      <td>0.578283</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>nb</td>\n      <td>5.498723e-07</td>\n      <td>5.498723e-07</td>\n    </tr>\n    <tr>\n      <th>Synset('mess_jacket.n.01')</th>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>1.652238</td>\n      <td>11</td>\n      <td>3</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>1.454007e-08</td>\n      <td>1.454007e-08</td>\n    </tr>\n    <tr>\n      <th>Synset('long_johns.n.01')</th>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.479149</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>8.935307e-08</td>\n      <td>8.935307e-08</td>\n    </tr>\n    <tr>\n      <th>Synset('undies.n.01')</th>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>0.280880</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>2.118603e-07</td>\n      <td>2.118603e-07</td>\n    </tr>\n    <tr>\n      <th>Synset('lingerie.n.01')</th>\n      <td>garm</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.561761</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>nb</td>\n      <td>9.058988e-07</td>\n      <td>9.058988e-07</td>\n    </tr>\n  </tbody>\n</table>\n<p>839 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_GS_adppt = pd.read_csv('./features_google_ngram.csv', index_col=0)\n",
    "\n",
    "new_GS_adppt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}