{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import torch\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## English semantic features data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "           cue translated\n0      abandon     desert\n1      abandon       give\n2      abandon      leave\n5      abandon         up\n6      abandon   withdraw\n...        ...        ...\n69271     true     honest\n69274     true       real\n69277     true      right\n69280     true      truth\n69283     true      false\n\n[42616 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cue</th>\n      <th>translated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abandon</td>\n      <td>desert</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abandon</td>\n      <td>give</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abandon</td>\n      <td>leave</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>abandon</td>\n      <td>up</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>abandon</td>\n      <td>withdraw</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>69271</th>\n      <td>true</td>\n      <td>honest</td>\n    </tr>\n    <tr>\n      <th>69274</th>\n      <td>true</td>\n      <td>real</td>\n    </tr>\n    <tr>\n      <th>69277</th>\n      <td>true</td>\n      <td>right</td>\n    </tr>\n    <tr>\n      <th>69280</th>\n      <td>true</td>\n      <td>truth</td>\n    </tr>\n    <tr>\n      <th>69283</th>\n      <td>true</td>\n      <td>false</td>\n    </tr>\n  </tbody>\n</table>\n<p>42616 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_features_raw = pd.read_excel('./final_words_2017.xlsx')\n",
    "english_features = english_features_raw[['cue', 'translated']]\n",
    "english_features = english_features.drop_duplicates()\n",
    "english_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BART pre-trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /export/scratch2/home/haochen/.cache/torch/hub/pytorch_fairseq_main\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_93507/1613858109.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mbart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhub\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'pytorch/fairseq'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'bart.large'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mbart\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/hub.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(repo_or_dir, model, source, force_reload, verbose, skip_validation, *args, **kwargs)\u001B[0m\n\u001B[1;32m    402\u001B[0m         \u001B[0mrepo_or_dir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_cache_or_reload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrepo_or_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_reload\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskip_validation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    403\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 404\u001B[0;31m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_load_local\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrepo_or_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    405\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    406\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/hub.py\u001B[0m in \u001B[0;36m_load_local\u001B[0;34m(hubconf_dir, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    428\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    429\u001B[0m     \u001B[0mhubconf_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhubconf_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mMODULE_HUBCONF\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 430\u001B[0;31m     \u001B[0mhub_module\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_import_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMODULE_HUBCONF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhubconf_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    431\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    432\u001B[0m     \u001B[0mentry\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_load_entry_from_hubconf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhub_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/hub.py\u001B[0m in \u001B[0;36m_import_module\u001B[0;34m(name, path)\u001B[0m\n\u001B[1;32m     74\u001B[0m     \u001B[0mmodule\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule_from_spec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mLoader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 76\u001B[0;31m     \u001B[0mspec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexec_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     77\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/importlib/_bootstrap_external.py\u001B[0m in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "\u001B[0;32m~/.cache/torch/hub/pytorch_fairseq_main/hubconf.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;31m# to build them here\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m     \u001B[0;32mimport\u001B[0m \u001B[0mfairseq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoken_block_utils_fast\u001B[0m  \u001B[0;31m# noqa\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m \u001B[0;32mexcept\u001B[0m \u001B[0mImportError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfairseq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlr_scheduler\u001B[0m  \u001B[0;31m# noqa\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfairseq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpdb\u001B[0m  \u001B[0;31m# noqa\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mfairseq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscoring\u001B[0m  \u001B[0;31m# noqa\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfairseq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtasks\u001B[0m  \u001B[0;31m# noqa\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfairseq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoken_generation_constraints\u001B[0m  \u001B[0;31m# noqa\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/scoring/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 34\u001B[0;31m _build_scorer, register_scorer, SCORER_REGISTRY, _ = registry.setup_registry(\n\u001B[0m\u001B[1;32m     35\u001B[0m     \u001B[0;34m\"--scoring\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdefault\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"bleu\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m )\n",
      "\u001B[0;31mTypeError\u001B[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "bart = torch.hub.load('pytorch/fairseq', 'bart.large')\n",
    "bart.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}