{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score, balanced_accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                              Synsets domain_x  nrdirhypers_x  nrhypos_x  \\\n0    Synset('adjustable_wrench.n.01')     tool              1          7   \n1         Synset('allen_wrench.n.01')     tool              1          0   \n2     Synset('alligator_wrench.n.01')     tool              1          0   \n3                  Synset('awl.n.01')     tool              1          2   \n4              Synset('backsaw.n.01')     tool              1          0   \n..                                ...      ...            ...        ...   \n834       Synset('ballet_skirt.n.01')     garm              1          0   \n835        Synset('mess_jacket.n.01')     garm              1          0   \n836         Synset('long_johns.n.01')     garm              1          0   \n837             Synset('undies.n.01')     garm              1          0   \n838           Synset('lingerie.n.01')     garm              1          2   \n\n     nrpartrels_normalised_x  depthfromtopsynset_normalised_x  \\\n0                        0.0                         1.012903   \n1                        0.0                         1.012903   \n2                        0.0                         1.012903   \n3                       15.7                         0.911613   \n4                        0.0                         1.114194   \n..                       ...                              ...   \n834                      0.0                         0.947552   \n835                      0.0                         1.158120   \n836                      0.0                         1.052836   \n837                      0.0                         1.158120   \n838                      0.0                         1.052836   \n\n     glosslength_normalised_x  minwordlength_x  nroflemmas_x  polyscore_max_x  \\\n0                    0.563173               17             2                1   \n1                    0.391092               12             1                1   \n2                    1.517437               16             1                1   \n3                    0.985552                3             1                1   \n4                    1.110701                7             2                1   \n..                        ...              ...           ...              ...   \n834                  0.578283                4             2                2   \n835                  1.652238               11             3                1   \n836                  0.479149               10             1                1   \n837                  0.280880                6             1                1   \n838                  0.561761                8             2                1   \n\n     ... ngram_50y_mean  ngram_50y_max  ngram_100y_mean  ngram_100y_max  \\\n0    ...   2.667275e-08   5.067315e-08     2.252890e-08    5.067315e-08   \n1    ...   2.025710e-08   6.483798e-08     1.515313e-08    6.483798e-08   \n2    ...   1.955061e-10   5.970550e-10     6.184165e-10    7.804026e-09   \n3    ...   2.895038e-07   3.752697e-07     3.562540e-07    6.002532e-07   \n4    ...   1.620242e-08   2.446695e-08     1.704462e-08    2.446695e-08   \n..   ...            ...            ...              ...             ...   \n834  ...   4.059229e-07   8.004256e-07     2.485961e-07    8.004256e-07   \n835  ...   9.969528e-09   8.272560e-09     1.233276e-08    2.136213e-08   \n836  ...   4.974292e-08   1.103470e-07     2.680743e-08    1.103470e-07   \n837  ...   7.986401e-08   2.565946e-07     5.787213e-08    2.565946e-07   \n838  ...   5.858985e-07   1.126403e-06     4.927242e-07    1.126403e-06   \n\n     ngram_200y_mean  ngram_200y_max  ngram_400y_mean  ngram_400y_max  \\\n0       1.380492e-08    5.067315e-08     6.919673e-09    5.067315e-08   \n1       7.715051e-09    6.483798e-08     3.867145e-09    6.483798e-08   \n2       1.237592e-09    1.499339e-08     6.203393e-10    1.499339e-08   \n3       5.869817e-07    2.510665e-06     6.210211e-07    6.602901e-06   \n4       1.451245e-08    3.507272e-08     9.018908e-09    2.260505e-07   \n..               ...             ...              ...             ...   \n834     1.531570e-07    8.004256e-07     1.136149e-07    8.004256e-07   \n835     1.358353e-08    5.083992e-08     6.963715e-09    5.547362e-08   \n836     1.393969e-08    1.103470e-07     6.987224e-09    1.103470e-07   \n837     3.095668e-08    2.565946e-07     2.025520e-08    3.896998e-07   \n838     2.835355e-07    1.126403e-06     1.440483e-07    1.126403e-06   \n\n     ngram_500y_mean  ngram_500y_max  \n0       5.336133e-09    5.067315e-08  \n1       2.982164e-09    6.483798e-08  \n2       4.783770e-10    1.499339e-08  \n3       5.069033e-07    6.602901e-06  \n4       6.954965e-09    2.260505e-07  \n..               ...             ...  \n834     9.223624e-08    1.686392e-06  \n835     5.370096e-09    5.547362e-08  \n836     5.388225e-09    1.103470e-07  \n837     1.561987e-08    3.896998e-07  \n838     1.351753e-07    8.808865e-06  \n\n[839 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Synsets</th>\n      <th>domain_x</th>\n      <th>nrdirhypers_x</th>\n      <th>nrhypos_x</th>\n      <th>nrpartrels_normalised_x</th>\n      <th>depthfromtopsynset_normalised_x</th>\n      <th>glosslength_normalised_x</th>\n      <th>minwordlength_x</th>\n      <th>nroflemmas_x</th>\n      <th>polyscore_max_x</th>\n      <th>...</th>\n      <th>ngram_50y_mean</th>\n      <th>ngram_50y_max</th>\n      <th>ngram_100y_mean</th>\n      <th>ngram_100y_max</th>\n      <th>ngram_200y_mean</th>\n      <th>ngram_200y_max</th>\n      <th>ngram_400y_mean</th>\n      <th>ngram_400y_max</th>\n      <th>ngram_500y_mean</th>\n      <th>ngram_500y_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Synset('adjustable_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.563173</td>\n      <td>17</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2.667275e-08</td>\n      <td>5.067315e-08</td>\n      <td>2.252890e-08</td>\n      <td>5.067315e-08</td>\n      <td>1.380492e-08</td>\n      <td>5.067315e-08</td>\n      <td>6.919673e-09</td>\n      <td>5.067315e-08</td>\n      <td>5.336133e-09</td>\n      <td>5.067315e-08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Synset('allen_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>0.391092</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2.025710e-08</td>\n      <td>6.483798e-08</td>\n      <td>1.515313e-08</td>\n      <td>6.483798e-08</td>\n      <td>7.715051e-09</td>\n      <td>6.483798e-08</td>\n      <td>3.867145e-09</td>\n      <td>6.483798e-08</td>\n      <td>2.982164e-09</td>\n      <td>6.483798e-08</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Synset('alligator_wrench.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.012903</td>\n      <td>1.517437</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.955061e-10</td>\n      <td>5.970550e-10</td>\n      <td>6.184165e-10</td>\n      <td>7.804026e-09</td>\n      <td>1.237592e-09</td>\n      <td>1.499339e-08</td>\n      <td>6.203393e-10</td>\n      <td>1.499339e-08</td>\n      <td>4.783770e-10</td>\n      <td>1.499339e-08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Synset('awl.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15.7</td>\n      <td>0.911613</td>\n      <td>0.985552</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2.895038e-07</td>\n      <td>3.752697e-07</td>\n      <td>3.562540e-07</td>\n      <td>6.002532e-07</td>\n      <td>5.869817e-07</td>\n      <td>2.510665e-06</td>\n      <td>6.210211e-07</td>\n      <td>6.602901e-06</td>\n      <td>5.069033e-07</td>\n      <td>6.602901e-06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Synset('backsaw.n.01')</td>\n      <td>tool</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.114194</td>\n      <td>1.110701</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.620242e-08</td>\n      <td>2.446695e-08</td>\n      <td>1.704462e-08</td>\n      <td>2.446695e-08</td>\n      <td>1.451245e-08</td>\n      <td>3.507272e-08</td>\n      <td>9.018908e-09</td>\n      <td>2.260505e-07</td>\n      <td>6.954965e-09</td>\n      <td>2.260505e-07</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>834</th>\n      <td>Synset('ballet_skirt.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.947552</td>\n      <td>0.578283</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4.059229e-07</td>\n      <td>8.004256e-07</td>\n      <td>2.485961e-07</td>\n      <td>8.004256e-07</td>\n      <td>1.531570e-07</td>\n      <td>8.004256e-07</td>\n      <td>1.136149e-07</td>\n      <td>8.004256e-07</td>\n      <td>9.223624e-08</td>\n      <td>1.686392e-06</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>Synset('mess_jacket.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>1.652238</td>\n      <td>11</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>9.969528e-09</td>\n      <td>8.272560e-09</td>\n      <td>1.233276e-08</td>\n      <td>2.136213e-08</td>\n      <td>1.358353e-08</td>\n      <td>5.083992e-08</td>\n      <td>6.963715e-09</td>\n      <td>5.547362e-08</td>\n      <td>5.370096e-09</td>\n      <td>5.547362e-08</td>\n    </tr>\n    <tr>\n      <th>836</th>\n      <td>Synset('long_johns.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.479149</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4.974292e-08</td>\n      <td>1.103470e-07</td>\n      <td>2.680743e-08</td>\n      <td>1.103470e-07</td>\n      <td>1.393969e-08</td>\n      <td>1.103470e-07</td>\n      <td>6.987224e-09</td>\n      <td>1.103470e-07</td>\n      <td>5.388225e-09</td>\n      <td>1.103470e-07</td>\n    </tr>\n    <tr>\n      <th>837</th>\n      <td>Synset('undies.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.158120</td>\n      <td>0.280880</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>7.986401e-08</td>\n      <td>2.565946e-07</td>\n      <td>5.787213e-08</td>\n      <td>2.565946e-07</td>\n      <td>3.095668e-08</td>\n      <td>2.565946e-07</td>\n      <td>2.025520e-08</td>\n      <td>3.896998e-07</td>\n      <td>1.561987e-08</td>\n      <td>3.896998e-07</td>\n    </tr>\n    <tr>\n      <th>838</th>\n      <td>Synset('lingerie.n.01')</td>\n      <td>garm</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.052836</td>\n      <td>0.561761</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>5.858985e-07</td>\n      <td>1.126403e-06</td>\n      <td>4.927242e-07</td>\n      <td>1.126403e-06</td>\n      <td>2.835355e-07</td>\n      <td>1.126403e-06</td>\n      <td>1.440483e-07</td>\n      <td>1.126403e-06</td>\n      <td>1.351753e-07</td>\n      <td>8.808865e-06</td>\n    </tr>\n  </tbody>\n</table>\n<p>839 rows Ã— 29 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing for the dataset\n",
    "ngram_dataset = pd.read_csv('./features_google_ngram.csv', index_col=None)\n",
    "ngram_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# define features and target\n",
    "features_base = ['nrdirhypers_x',\n",
    "            'nrhypos_x',\n",
    "            'nrpartrels_normalised_x',\n",
    "            'depthfromtopsynset_normalised_x',\n",
    "            'glosslength_normalised_x',\n",
    "            'minwordlength_x',\n",
    "            'nroflemmas_x',\n",
    "            'polyscore_max_x']\n",
    "target = ['vote_x'] # nb / b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GlobalModel Test\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# split training set and testing set using K-Flod\n",
    "def global_model_test(dataset, feature, year_period, target):\n",
    "    K = 10\n",
    "    random_seed = 7 # R\n",
    "    data = dataset.reset_index()\n",
    "    feature_list = feature + [year_period]\n",
    "    X = data[feature_list]\n",
    "    y = data[target]\n",
    "\n",
    "    K_Flod = StratifiedKFold(n_splits=K, shuffle=True, random_state=random_seed)\n",
    "    K_Flod.get_n_splits(X, y)\n",
    "    cohen_kappa = []\n",
    "    balanced_acc = []\n",
    "    for train_index, test_index in K_Flod.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # SMOTE algorithm\n",
    "        smote = SMOTE(random_state=random_seed, k_neighbors=2)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # define random forest model\n",
    "        rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "        # predict and make score\n",
    "        pipeline = make_pipeline(smote, rf)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "        cohen_kappa.append(kappa)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        balanced_acc.append(balanced_accuracy)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    results.append(np.mean(cohen_kappa))\n",
    "    results.append(np.mean(balanced_acc))\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.6889932540972804, 0.8458398737152029]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model_test(ngram_dataset, features_base, 'ngram_10y_mean', target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "ngram_feature_list = ['ngram_1y_mean', 'ngram_1y_max',\n",
    "                      'ngram_5y_mean', 'ngram_5y_max',\n",
    "                      'ngram_10y_mean', 'ngram_10y_max',\n",
    "                      'ngram_20y_mean', 'ngram_20y_max',\n",
    "                      'ngram_50y_mean', 'ngram_50y_max',\n",
    "                      'ngram_100y_mean', 'ngram_100y_max',\n",
    "                      'ngram_200y_mean', 'ngram_200y_max',\n",
    "                      'ngram_400y_mean', 'ngram_400y_max',\n",
    "                      'ngram_500y_mean', 'ngram_500y_max']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_kappa_dict = {'mean': [], 'max': []}\n",
    "result_balancedAcc_dict = {'mean': [], 'max': []}\n",
    "for counter in range(len(ngram_feature_list)):\n",
    "    result_list = global_model_test(ngram_dataset, features_base, ngram_feature_list[counter], target)\n",
    "    if counter % 2 == 0:\n",
    "        result_kappa_dict['mean'].append(result_list[0])\n",
    "        result_balancedAcc_dict['mean'].append(result_list[1])\n",
    "    else:\n",
    "        result_kappa_dict['max'].append(result_list[0])\n",
    "        result_balancedAcc_dict['max'].append(result_list[1])\n",
    "\n",
    "np.save('./resultDict/GlobalModel_Test_kappa.npy', result_kappa_dict, allow_pickle=True)\n",
    "np.save('./resultDict/GlobalModel_Test_balanced_acc.npy', result_balancedAcc_dict, allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean': [0.6895131395336889,\n  0.6819311995908929,\n  0.6889932540972804,\n  0.6894450582550637,\n  0.6792460904959001,\n  0.670646830216902,\n  0.6832672806178925,\n  0.6741536864265807,\n  0.6821740987639083],\n 'max': [0.6863100162923843,\n  0.6974403198307233,\n  0.6935090842995564,\n  0.6924517230386286,\n  0.6897699544263008,\n  0.6996241732892688,\n  0.6958277302930723,\n  0.6831921751429977,\n  0.6863755367076694]}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_kappa_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean': [0.6895131395336889,\n  0.6819311995908929,\n  0.6889932540972804,\n  0.6894450582550637,\n  0.6792460904959001,\n  0.670646830216902,\n  0.6832672806178925,\n  0.6741536864265807,\n  0.6821740987639083],\n 'max': [0.6863100162923843,\n  0.6974403198307233,\n  0.6935090842995564,\n  0.6924517230386286,\n  0.6897699544263008,\n  0.6996241732892688,\n  0.6958277302930723,\n  0.6831921751429977,\n  0.6863755367076694]}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./resultDict/GlobalModel_Test_kappa.npy', allow_pickle=True).item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LocalModel Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# generate the local dataframe for different domains\n",
    "local_fruit = ngram_dataset.loc[ngram_dataset['domain_x']=='fruit']\n",
    "local_tool = ngram_dataset.loc[ngram_dataset['domain_x']=='tool']\n",
    "local_music = ngram_dataset.loc[ngram_dataset['domain_x']=='music']\n",
    "local_furniture = ngram_dataset.loc[ngram_dataset['domain_x']=='furn']\n",
    "local_garments = ngram_dataset.loc[ngram_dataset['domain_x']=='garm']\n",
    "\n",
    "local_list = [local_fruit, local_tool, local_music, local_furniture, local_garments]\n",
    "\n",
    "# average results of five domains\n",
    "def local_model_test(dataset_list, feature, year_period, target):\n",
    "    local_kappa_list = []\n",
    "    local_balancedAcc_list = []\n",
    "    for local_dataset in dataset_list:\n",
    "        result_list = global_model_test(local_dataset, feature, year_period, target)\n",
    "        local_kappa_list.append(result_list[0])\n",
    "        local_balancedAcc_list.append(result_list[1])\n",
    "\n",
    "    local_result_list = [np.mean(local_kappa_list), np.mean(local_balancedAcc_list)]\n",
    "    return local_result_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.6709395758983121, 0.8410339954163485]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_test(local_list, features_base, 'ngram_10y_mean', target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_local_kappa_dict = {'mean': [], 'max': []}\n",
    "result_local_balancedAcc_dict = {'mean': [], 'max': []}\n",
    "for counter in range(len(ngram_feature_list)):\n",
    "    result_list = local_model_test(local_list, features_base, ngram_feature_list[counter], target)\n",
    "    if counter % 2 == 0:\n",
    "        result_local_kappa_dict['mean'].append(result_list[0])\n",
    "        result_local_balancedAcc_dict['mean'].append(result_list[1])\n",
    "    else:\n",
    "        result_local_kappa_dict['max'].append(result_list[0])\n",
    "        result_local_balancedAcc_dict['max'].append(result_list[1])\n",
    "\n",
    "np.save('./resultDict/LocallModel_Test_kappa.npy', result_local_kappa_dict, allow_pickle=True)\n",
    "np.save('./resultDict/LocalModel_Test_balanced_acc.npy', result_local_balancedAcc_dict, allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean': [0.6567146798792984,\n  0.6724061180707366,\n  0.6709395758983121,\n  0.6798979095646819,\n  0.6715040349208072,\n  0.6774458425156835,\n  0.6642376222592066,\n  0.6646532349454074,\n  0.6620570810992537],\n 'max': [0.6567146798792984,\n  0.6563639250405917,\n  0.6712321684909046,\n  0.6689357328525052,\n  0.6732312560304884,\n  0.6700983550264065,\n  0.6666929725206334,\n  0.664470135293054,\n  0.6747046841570868]}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_local_kappa_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TransferModel Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# generate the unseen(transfer) dataframe for different domains\n",
    "unseen_fruit = ngram_dataset.loc[ngram_dataset['domain_x']!='fruit']\n",
    "unseen_tool = ngram_dataset.loc[ngram_dataset['domain_x']!='tool']\n",
    "unseen_music = ngram_dataset.loc[ngram_dataset['domain_x']!='music']\n",
    "unseen_furniture = ngram_dataset.loc[ngram_dataset['domain_x']!='furn']\n",
    "unseen_garments = ngram_dataset.loc[ngram_dataset['domain_x']!='garm']\n",
    "\n",
    "unseen_list = [unseen_fruit, unseen_tool, unseen_music, unseen_furniture, unseen_garments]\n",
    "\n",
    "def transfer_model_test(train_list, test_list, feature, year_period, target):\n",
    "    random_seed = 7 # R\n",
    "    transfer_kappa_list = []\n",
    "    transfer_balancedAcc_list = []\n",
    "    for counter in range(len(train_list)):\n",
    "        training_data = train_list[counter].reset_index()\n",
    "        testing_data = test_list[counter].reset_index()\n",
    "        feature_list = feature + [year_period]\n",
    "        X_train = training_data[feature_list]\n",
    "        y_train = training_data[target]\n",
    "        X_test = testing_data[feature_list]\n",
    "        y_test = testing_data[target]\n",
    "\n",
    "        # SMOTE algorithm\n",
    "        smote = SMOTE(random_state=random_seed, k_neighbors=2)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # define random forest model\n",
    "        rf = RandomForestClassifier(random_state=random_seed, max_features='sqrt', n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_depth=50, oob_score=True, criterion='gini', bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "        # predict and make score\n",
    "        pipeline = make_pipeline(smote, rf)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "        transfer_kappa_list.append(kappa)\n",
    "        transfer_balancedAcc_list.append(balanced_accuracy)\n",
    "\n",
    "    transfer_results = [np.mean(transfer_kappa_list), np.mean(transfer_balancedAcc_list)]\n",
    "\n",
    "    return transfer_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.5143881523591414, 0.7994906201379257]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "transfer_model_test(unseen_list, local_list, features_base, 'ngram_10y_mean', target)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ngram_feature_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_24320/390068985.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mresult_transfer_kappa_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'mean'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'max'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mresult_transfer_balancedAcc_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'mean'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'max'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mcounter\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mngram_feature_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0mresult_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtransfer_model_test\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0munseen_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocal_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatures_base\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mngram_feature_list\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcounter\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcounter\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ngram_feature_list' is not defined"
     ]
    }
   ],
   "source": "result_transfer_kappa_dict = {'mean': [], 'max': []}\nresult_transfer_balancedAcc_dict = {'mean': [], 'max': []}\nfor counter in range(len(ngram_feature_list)):\n    result_list = transfer_model_test(unseen_list, local_list, features_base, ngram_feature_list[counter], target)\n    if counter % 2 == 0:\n        result_transfer_kappa_dict['mean'].append(result_list[0])\n        result_transfer_balancedAcc_dict['mean'].append(result_list[1])\n    else:\n        result_transfer_kappa_dict['max'].append(result_list[0])\n        result_transfer_balancedAcc_dict['max'].append(result_list[1])\n\nnp.save('./resultDict/TransferModel_Test_kappa.npy', result_local_kappa_dict, allow_pickle=True)\nnp.save('./resultDict/TransferModel_Test_balanced_acc.npy', result_local_balancedAcc_dict, allow_pickle=True)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": "np.save('./resultDict/TransferModel_Test_kappa.npy', result_transfer_kappa_dict, allow_pickle=True)\nnp.save('./resultDict/TransferModel_Test_balanced_acc.npy', result_transfer_balancedAcc_dict, allow_pickle=True)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean': [0.8012823577114185,\n  0.7994100172858866,\n  0.7994906201379257,\n  0.8090529575073312,\n  0.8070534017778341,\n  0.8096072322785901,\n  0.8015649334468173,\n  0.7968861624641281,\n  0.8005593258284028],\n 'max': [0.8029526850251582,\n  0.7998985804659886,\n  0.7978959710769363,\n  0.8038465068312959,\n  0.802898041832595,\n  0.807515347964346,\n  0.8029281008817364,\n  0.7986516512985293,\n  0.7949540599272693]}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "result_transfer_balancedAcc_dict",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}